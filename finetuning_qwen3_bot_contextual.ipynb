{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf9dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA RTX 4500 Ada Generation. Num GPUs = 1. Max memory: 23.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bf16_supported\n",
    "import torch\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "max_seq_length = 4096\n",
    "lora_rank = 64\n",
    "dtype = None\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"./models/unsloth-Qwen3-0.6B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True,\n",
    "    dtype = dtype\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe1828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- messages[0].content + '\\n\\n' }}\n",
      "    {%- endif %}\n",
      "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
      "{%- for forward_message in messages %}\n",
      "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
      "    {%- set message = messages[index] %}\n",
      "    {%- set current_content = message.content if message.content is defined and message.content is not none else '' %}\n",
      "    {%- set tool_start = '<tool_response>' %}\n",
      "    {%- set tool_start_length = tool_start|length %}\n",
      "    {%- set start_of_message = current_content[:tool_start_length] %}\n",
      "    {%- set tool_end = '</tool_response>' %}\n",
      "    {%- set tool_end_length = tool_end|length %}\n",
      "    {%- set start_pos = (current_content|length) - tool_end_length %}\n",
      "    {%- if start_pos < 0 %}\n",
      "        {%- set start_pos = 0 %}\n",
      "    {%- endif %}\n",
      "    {%- set end_of_message = current_content[start_pos:] %}\n",
      "    {%- if ns.multi_step_tool and message.role == \"user\" and not(start_of_message == tool_start and end_of_message == tool_end) %}\n",
      "        {%- set ns.multi_step_tool = false %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {%- set m_content = message.content if message.content is defined and message.content is not none else '' %}\n",
      "        {%- set content = m_content %}\n",
      "        {%- set reasoning_content = '' %}\n",
      "        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n",
      "            {%- set reasoning_content = message.reasoning_content %}\n",
      "        {%- else %}\n",
      "            {%- if '</think>' in m_content %}\n",
      "                {%- set content = (m_content.split('</think>')|last).lstrip('\\n') %}\n",
      "                {%- set reasoning_content = (m_content.split('</think>')|first).rstrip('\\n') %}\n",
      "                {%- set reasoning_content = (reasoning_content.split('<think>')|last).lstrip('\\n') %}\n",
      "            {%- endif %}\n",
      "        {%- endif %}\n",
      "        {%- if loop.index0 > ns.last_query_index %}\n",
      "            {%- if loop.last or (not loop.last and (not reasoning_content.strip() == '')) %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
      "            {%- else %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "            {%- endif %}\n",
      "        {%- else %}\n",
      "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "        {%- endif %}\n",
      "        {%- if message.tool_calls %}\n",
      "            {%- for tool_call in message.tool_calls %}\n",
      "                {%- if (loop.first and content) or (not loop.first) %}\n",
      "                    {{- '\\n' }}\n",
      "                {%- endif %}\n",
      "                {%- if tool_call.function %}\n",
      "                    {%- set tool_call = tool_call.function %}\n",
      "                {%- endif %}\n",
      "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
      "                {{- tool_call.name }}\n",
      "                {{- '\", \"arguments\": ' }}\n",
      "                {%- if tool_call.arguments is string %}\n",
      "                    {{- tool_call.arguments }}\n",
      "                {%- else %}\n",
      "                    {{- tool_call.arguments | tojson }}\n",
      "                {%- endif %}\n",
      "                {{- '}\\n</tool_call>' }}\n",
      "            {%- endfor %}\n",
      "        {%- endif %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "    {%- if enable_thinking is defined and enable_thinking is false %}\n",
      "        {{- '<think>\\n\\n</think>\\n\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9145c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0061, -0.0928,  0.0251,  ...,  0.0051, -0.0082, -0.0054],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Formatted output:\n",
      " <|im_start|>system\n",
      "Responde usando el contexto<|im_end|>\n",
      "<|im_start|>context\n",
      "Qwen 2.5 tiene 128K de contexto<|im_end|>\n",
      "<|im_start|>user\n",
      "¬øCu√°nto contexto soporta Qwen?<|im_end|>\n",
      "<|im_start|>assistant<think>\n",
      "\n",
      "</think>\n"
     ]
    }
   ],
   "source": [
    "#from transformers import AutoTokenizer\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"./models/Qwen2.5-0.5B\")\n",
    "\n",
    "# 2. Definir manualmente el chat_template con soporte para contextos\n",
    "\n",
    "## Contextual Etiqueta\n",
    "new_tokens = [\"<|im_start|>context\", \"<|context|>\"]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "token_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>context\")\n",
    "print(model.get_input_embeddings().weight[token_id])\n",
    "\n",
    "custom_chat_template = \"\"\"{% for message in messages %}\n",
    "{% if message['role'] == 'system' %}\n",
    "<|im_start|>system\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% elif message['role'] == 'context' %}\n",
    "<|im_start|>context\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% elif message['role'] == 'user' %}\n",
    "<|im_start|>user\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% elif message['role'] == 'assistant' %}\n",
    "<|im_start|>assistant\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "{%- if add_generation_prompt %}\n",
    "<|im_start|>assistant\n",
    "{%- if enable_thinking is defined and enable_thinking == false %}\n",
    "<think>\n",
    "\n",
    "</think>\n",
    "\n",
    "{%- endif %}\n",
    "{% endif %}\"\"\"\n",
    "# 3. Asignar la plantilla personalizada\n",
    "tokenizer.chat_template = custom_chat_template\n",
    "\n",
    "# 4. Verificar que funciona\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Responde usando el contexto\"},\n",
    "    {\"role\": \"context\", \"content\": \"Qwen 2.5 tiene 128K de contexto\"},\n",
    "    {\"role\": \"user\", \"content\": \"¬øCu√°nto contexto soporta Qwen?\"},\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking = False\n",
    ")\n",
    "\n",
    "print(\"Formatted output:\\n\", formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd8c9729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0061, -0.0928,  0.0251,  ...,  0.0051, -0.0082, -0.0054],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "token_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>context\")\n",
    "print(model.get_input_embeddings().weight[token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b139024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Escuelas Profesionales de la Facultad de Ciencias de la UNI\\n\\nInformaci√≥n de Contacto:\\nSeg√∫n la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\\n\\nPara F√≠sica, Qu√≠mica o Ciencia de la Computaci√≥n: escuelas_fc1@uni.edu.pe\\nPara Matem√°ticas o Ingenier√≠a F√≠sica: escuelas_fc2@uni.edu.pe\\n\\nHorario de Atenci√≥n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\\n\\n√Årea de Estad√≠stica y Registros Acad√©micos de la Facultad de Ciencias de la UNI\\n\\nInformaci√≥n de Contacto de la oficina de estad√≠stica (AERA)\\nE-mail: estadistica_fc@uni.edu.pe\\n\\nHorario de Atenci√≥n de la oficina de estad√≠stica (AERA):\\nDe Lunes a Viernes de 8:00 a.m. a 4:00 p.m.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_fragment_doc\n",
    "general_contact_information = read_fragment_doc(\"./documentos/informacion_general_contacto.txt\")\n",
    "general_contact_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7a20765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}\n",
      "{% if message['role'] == 'system' %}\n",
      "<|im_start|>system\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'context' %}\n",
      "<|im_start|>context\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'user' %}\n",
      "<|im_start|>user\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'assistant' %}\n",
      "<|im_start|>assistant\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% endif %}\n",
      "{% endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "<|im_start|>assistant\n",
      "{%- if enable_thinking is defined and enable_thinking == false %}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{%- endif %}\n",
      "{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51da1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matr√≠cula, procedimientos y tr√°mites acad√©micos de la Facultad de Ciencias de la Universidad Nacional de Ingenier√≠a del Per√∫.\n",
      "Deber√°s responder a los mensajes asegur√°ndote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, √∫tiles y concisas a las preguntas del usuario bas√°ndote exclusivamente en el contexto proporcionado.\n",
      "    2. Mant√©n un tono cordial, emp√°tico y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina m√°s id√≥nea, la derivaci√≥n se realizar√° hacia la Oficina de Estad√≠stica (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empat√≠a que no tienes acceso a dicha informaci√≥n.<|im_end|>\n",
      "<|im_start|>context\n",
      "Fecha De Pago De Autoseguro\n",
      "¬øHasta que fecha se debe realizar el pago por concepto de autoseguro estudiantil para que un estudiante pueda realizar la matr√≠cula regular al ciclo academico en la Facultad de Ciencias de la UNI?\n",
      "Los estudiantes deben realizar el pago del autoseguro estudiantil antes de las fechas de matr√≠cula, dentro del plazo m√°ximo establecido en el calendario de actividades acad√©micas correspondiente al periodo acad√©mico. Si no se cumple con este plazo m√°ximo, no se habilitar√° en el sistema su matricula regular (inscripci√≥n de cursos) y deber√° gestionar la matricula como rezagada. El estudiante puede verificar esta situaci√≥n al comprobar si su matr√≠cula se habilita o no en las fechas de matr√≠cula regular. Si la matr√≠cula no se habilita en estas fechas, el estudiante podr√° solicitar su matricula rezagada. Sin embargo, la inscripci√≥n de cursos de la matricula rezagada se realiza en funci√≥n de las vacantes disponibles por lo que se corre el riesgo de no alcanzar vacantes para los cursos deseados.\n",
      "El calendario de actividades acad√©micas es publicado en la secci√≥n \"MATR√çCULA Y PROCEDIMIENTOS\" de la pagina web de la Facultad de Ciencias, puede acceder a esta secci√≥n de la web mediante el siguiente enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Procedimiento De Matricula Rezagada\n",
      "¬øQu√© procedimiento debe seguir un estudiante de pregrado de la facultad de ciencias de la uni para tramitar su matricula rezagada?\n",
      "La matr√≠cula rezagada se realiza en las fechas establecidas en el calendario de actividades acad√©micas publicado dentro de la secci√≥n [\"MATR√çCULA Y PROCEDIMIENTOS\" de la Pagina de la Facultad de Ciencias](https://fc.uni.edu.pe/estadistica/documentos/). Esta matr√≠cula est√° dirigida a los alumnos ingresantes que no pudieron matricularse en las fechas establecidas en el calendario de actividades acad√©micas, as√≠ como a los alumnos regulares que no realizaron su matr√≠cula regular acad√©mica en el plazo correspondiente y a los estudiantes reincorporados rezagados.\n",
      "Para poder efectuar la matr√≠cula rezagada, el estudiante no debe tener adeudos pendientes con la facultad ya sea por concepto econ√≥mico, pr√©stamos de libros u otros materiales de ense√±anza en general de la biblioteca y debe haber realizado el pago por concepto de autoseguro m√©dico estudiantil.\n",
      "Cumplidos estos requisitos, deber√° seguir los siguientes pasos para completar el proceso::\n",
      "1. Previo a la matr√≠cula rezagada, el estudiante deber√° efectuar el pago de S/ 26. Para ello, debe generar la orden de pago por concepto de matricula rezagada a trav√©s del portal INTRALU y realizar el pago correspondiente en una agencia del BCP o mediante su banca m√≥vil.\n",
      "2. La matr√≠cula rezagada se realizar√° exclusivamente a trav√©s de la Oficina de Estad√≠stica (AERA) de la Facultad, en las fechas establecidas en el calendario de actividades acad√©micas. Para ello, el estudiante deber√° presentarse en dichas fechas en la Oficina de Estad√≠stica con el comprobante de pago correspondiente.\n",
      "\n",
      "Posterior a la fechas de la matricula rezagada, los estudiantes ya no podr√°n realizar la matricula en el ciclo acad√©mico.\n",
      "\n",
      "Problemas Al Realizar La Matr√≠cula Virtual\n",
      "¬øQu√© debe hacer un estudiante si presenta problemas para realizar la matricula de sus cursos a traves del modulo de Matr√≠cula UNI dentro de la plataforma de intranet-alumnos?\n",
      "Los estudiantes que encuentren dificultades para completar su proceso de inscripci√≥n de cursos a traves del modulo de Matr√≠cula UNI dentro de la plataforma de intranet-alumnos deben verificar si se encuentran en alguna de las siguientes situaciones:\n",
      "    - Poseer alg√∫n tipo de adeudo con la Facultad. En caso de ser estudiante en riesgo acad√©mico y adeudar la tutor√≠a obligatoria previa a la matricula, deben ponerse en contacto con la Oficina de Tutor√≠a a trav√©s del correo electr√≥nico tutoria.fc@uni.edu.pe.\n",
      "\n",
      "    - No haber efectuado el pago del autoseguro en el plazo establecido en el calendario de actividades acad√©micas antes de las fechas de matricula. Si este es el caso y la matr√≠cula virtual (inscripci√≥n de cursos) no se ha habilitado hasta los d√≠as de matr√≠cula regular, es necesario comunicarse con la oficina de estad√≠stica (AERA) o revisar el procedimiento para gestionar su matr√≠cula rezagada.\n",
      "\n",
      "    - Para cualquier otro inconveniente, se recomienda ponerse en contacto directamente con la oficina de estad√≠stica (AERA), enviando un mensaje al correo estadistica_fc@uni.edu.pe o acercarse personalmente a dicha oficina.\n",
      "\n",
      "Perdida De Turno De Matricula\n",
      "¬øQu√© debe hacer un estudiante que no pudo realizar la inscripci√≥n de sus cursos de manera virtual en la fecha y turno asignado para su matr√≠cula regular?\n",
      "Si un estudiante no logr√≥ inscribirse en sus cursos a tiempo usando el M√≥dulo de Matr√≠cula UNI en la plataforma Intranet-Alumnos, seg√∫n los plazos establecidos en el calendario acad√©mico y en su turno asignado para la matr√≠cula regular del ciclo acad√©mico, pero a√∫n quiere inscribirse en el ciclo, deber√° gestionar su matr√≠cula rezagada.\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto:\n",
      "Seg√∫n la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para F√≠sica, Qu√≠mica o Ciencia de la Computaci√≥n: escuelas_fc1@uni.edu.pe\n",
      "Para Matem√°ticas o Ingenier√≠a F√≠sica: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "√Årea de Estad√≠stica y Registros Acad√©micos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto de la oficina de estad√≠stica (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de la oficina de estad√≠stica (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "Si un alumno no cumpli√≥ con el pago del autoseguro, ¬øqu√© procedimiento debe seguir para gestionar su matr√≠cula rezagada?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Si un alumno no cumpli√≥ con el pago del autoseguro, no podr√° realizar la matr√≠cula rezagada. Para gestionar su matr√≠cula rezagada, primero debe realizar el pago del autoseguro m√©dico estudiantil. Luego, deber√° seguir estos pasos:\n",
      "\n",
      "1. Generar la orden de pago por concepto de matr√≠cula rezagada a trav√©s del portal INTRALU y realizar el pago correspondiente de S/ 26 en una agencia del BCP o mediante su banca m√≥vil.\n",
      "2. Presentarse en la Oficina de Estad√≠stica (AERA) en las fechas establecidas en el calendario de actividades acad√©micas, llevando el comprobante de pago.\n",
      "\n",
      "Recuerde que la matr√≠cula rezagada se realiza solo si se cumplen todos los requisitos y en las fechas establecidas.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from datasets import load_dataset\n",
    "\n",
    "prompt_role_system = \"\"\"Eres Aerito, un asistente de IA especializado en temas de matr√≠cula, procedimientos y tr√°mites acad√©micos de la Facultad de Ciencias de la Universidad Nacional de Ingenier√≠a del Per√∫.\n",
    "Deber√°s responder a los mensajes asegur√°ndote de cumplir con los siguientes criterios.\n",
    "    1. Proporcionar respuestas informativas, √∫tiles y concisas a las preguntas del usuario bas√°ndote exclusivamente en el contexto proporcionado.\n",
    "    2. Mant√©n un tono cordial, emp√°tico y servicial en sus interacciones.\n",
    "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina m√°s id√≥nea, la derivaci√≥n se realizar√° hacia la Oficina de Estad√≠stica (AERA) de la Facultad de Ciencias.\n",
    "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empat√≠a que no tienes acceso a dicha informaci√≥n.\"\"\"\n",
    "\n",
    "#tokenizer = get_chat_template(\n",
    "#    tokenizer,\n",
    "#    chat_template = \"qwen-2.5\"\n",
    "#)\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"turns\"]\n",
    "    recovered_texts = examples[\"retrieved_texts\"]\n",
    "    docs_range = examples[\"docs_range\"]\n",
    "\n",
    "    #\"recovered_texts= examples[\"recovered_texts\"],\n",
    "    for convo, texts, doc_range in zip(convos, recovered_texts, docs_range):\n",
    "        if convo[0][\"role\"] != \"system\":\n",
    "            convo.insert(0, {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt_role_system\n",
    "            })\n",
    "            \n",
    "            if texts is not None:\n",
    "                #print(\"texts\", texts)\n",
    "                texts_context = [text[\"text\"] for text in texts[doc_range[0]:doc_range[1]]] + [general_contact_information]\n",
    "                context = \"\\n\\n\".join(texts_context)\n",
    "            \n",
    "                convo.insert(1, {\n",
    "                    \"role\": \"context\",\n",
    "                    \"content\": context\n",
    "                })\n",
    "                #print(\"convo[1]\",convo[1])\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files = {\"train\":\"./conversational_faq/data/train_turns_dataset.json\", \"val\": \"./conversational_faq/data/val_turns_dataset.json\"})\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "print(dataset['train'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60cd19cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5821/5821 [00:08<00:00, 725.77 examples/s]\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1919/1919 [00:07<00:00, 267.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import is_bf16_supported\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset['train'],\n",
    "    eval_dataset = dataset['val'],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 4,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field= \"text\",\n",
    "        per_device_train_batch_size = 16,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        per_device_eval_batch_size = 8,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=1,\n",
    "        #max_steps=60,\n",
    "        learning_rate= 2e-4,\n",
    "        fp16= not is_bf16_supported(),\n",
    "        bf16= is_bf16_supported(),\n",
    "        logging_steps=1,\n",
    "        eval_strategy= \"epoch\",\n",
    "        save_strategy= \"epoch\",\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        packing = False\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0726108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matr√≠cula, procedimientos y tr√°mites acad√©micos de la Facultad de Ciencias de la Universidad Nacional de Ingenier√≠a del Per√∫.\n",
      "Deber√°s responder a los mensajes asegur√°ndote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, √∫tiles y concisas a las preguntas del usuario bas√°ndote exclusivamente en el contexto proporcionado.\n",
      "    2. Mant√©n un tono cordial, emp√°tico y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina m√°s id√≥nea, la derivaci√≥n se realizar√° hacia la Oficina de Estad√≠stica (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empat√≠a que no tienes acceso a dicha informaci√≥n.<|im_end|>\n",
      "<|im_start|>context\n",
      "Generaci√≥n De Orden De Pago Para Autoseguro\n",
      "¬øCual es el proceso para que un ingresante o alumno regular genere una orden de pago para el pago de autoseguro?\n",
      "Para generar una orden de pago por concepto de autoseguro, el ingresante o alumno regular debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opci√≥n \"Tr√°mites\", para acceder al m√≥dulo de tramites y pagos. En dicho m√≥dulo, selecciona la opci√≥n \"PAGO-AUTOSEGURO MEDICO\" en el men√∫ desplegable, haz clic en el bot√≥n \"Nuevo\" y sigue las indicaciones hasta generar la orden de pago por el monto de S/. 55.00. Luego de generar la orden de pago el ingresante o estudiante regular podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria. Para mas detalles sobre el proceso para generar un orden de pago puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\n",
      "\n",
      "Procedimiento General Para Generar Una Orden De Pago\n",
      "¬øCu√°l es el procedimiento que debe seguir un estudiante para generar una orden de pago relacionada con alg√∫n concepto o tr√°mite espec√≠fico y realizar el pago correspondiente?\n",
      "Para generar una orden, el estudiante debe seguir los siguientes pasos:\n",
      "    1. Acceder a la plataforma INTRALU.\n",
      "    2. Dentro de la plataforma, seleccionar la opci√≥n \"Tr√°mites\" para acceder al m√≥dulo de tramites y pagos.\n",
      "    3. En el m√≥dulo de pagos, selecciona el tr√°mite correspondiente en el men√∫ desplegable. Despu√©s, haz clic en el bot√≥n \"Nuevo\" y siga las indicaciones hasta generar la orden de pago correspondiente.\n",
      "\n",
      "Para cualquier otro tr√°mite que no est√© estipulado en la lista de opciones dentro de la plataforma, solicitar la generaci√≥n de la orden de pago a la oficina de estad√≠stica (AERA) al correo estadistica_fc@uni.edu.pe, detallando el concepto del tramite y sus datos personales (DNI, apellidos, nombres, correo institucional) en el mensaje.\n",
      "\n",
      "Una vez generada la orden de pago, el alumno deber√° esperar aproximadamente 10 minutos para realizar el pago correspondiente en una sucursal del BCP o a trav√©s de la aplicaci√≥n m√≥vil del banco.\n",
      "\n",
      "Para obtener m√°s detalles sobre el proceso para generar una orden de pago a traves de la plataforma, consulta el Manual de Pagos publicado dentro de la secci√≥n de \"MATR√çCULA Y PROCEDIMIENTOS\" en la P√°gina Web de la Facultad de Ciencias, puede ingresar a dicha secci√≥n a traves del enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Proceso De Pago De Una Orden De Pago\n",
      "¬øComo pagar una orden de pago generada por el alg√∫n concepto o tramite?\n",
      "Los ingresantes o estudiantes de la Universidad Nacional de Ingenier√≠a, luego de generar una orden de pago por alg√∫n concepto o tr√°mite, pueden realizar el pago en alguna sucursal del BCP o a trav√©s de la aplicaci√≥n m√≥vil del banco. En la app, deben seleccionar \"Pagar servicios\", buscar a la Universidad Nacional de Ingenier√≠a y seleccionarla, luego elegir la opci√≥n de pago para estudiantes e ingresar su n√∫mero de DNI. La aplicaci√≥n mostrar√° la orden de pago con el monto exacto para realizar el pago.\n",
      "Se recomienda esperar al menos 10 minutos luego de generar la orden para realizar el pago correspondiente.\n",
      "\n",
      "Reincorporaci√≥n Despu√©s De Una Una Reserva De Matricula\n",
      "¬øQu√© procedimiento debe seguir un estudiante que desea reincorporarse despu√©s de haber reservado su matricula por uno o mas periodos acad√©micos?\n",
      "El estudiante que desee realizar su reincorporaci√≥n deber√° gestionarla antes de las fechas de matr√≠cula dentro del plazo establecido en el calendario de actividades acad√©micas. Para ello, debera realizar los siguientes pasos.\n",
      "    1. Acceder a la Portal INTRALU con su c√≥digo UNI y clave correspondiente. Luego, seleccionar la opci√≥n \"Tr√°mites\" para acceder al m√≥dulo de pagos.\n",
      "    2. En el m√≥dulo de pagos, seleccionar el tr√°mite correspondiente y genera una nueva orden de pago siguiendo las indicaciones en la plataforma. \n",
      "    3. Una vez generada la orden de pago, el alumno debe realizar el pago en una sucursal del BCP o utilizando la aplicaci√≥n m√≥vil del BCP. \n",
      "    4. Despu√©s de completar el pago, el estudiante debe enviar su solicitud de reincorporaci√≥n a trav√©s de la Plataforma de Intranet-Alumnos dentro de los plazos establecidos (consultar el calendario acad√©mico). Para ello accede a la plataforma, elige \"Reincorporaci√≥n de Estudiantes\" en \"Mis Tr√°mites\", completa el formulario con la solicitud y el comprobante de pago, y env√≠a la solicitud.\n",
      "\n",
      "Al completar el envi√≥ de la solicitud por la plataforma se visualizara la solicitud enviada, la fecha de envio y estado actual de la solicitud.\n",
      "Una vez aprobada y realizada la reincorporaci√≥n, el estudiante podr√° realizar su matr√≠cula de manera regular.\n",
      "\n",
      "Matricula Ingresantes\n",
      "Los nuevos ingresantes a la Facultad de Ciencias de la Universidad Nacional de Ingenieria, deberan seguir realizar el siguiente proceso para completar su matricula (primera matricula al primer ciclo):\n",
      "    1. Recabar su constancia de ingreso. Luego de gestionar la emisi√≥n de su constancia de ingreso, la Direcci√≥n de Admisi√≥n (DIAD) de la UNI enviar√° a su correo electr√≥nico la constancia de ingreso. Para m√°s detalles sobre el proceso, puede consultar con DIAD al correo informes.admision@uni.edu.pe. \n",
      "    2. Actualizacion de datos en DIRCE. La Direcci√≥n de Registros Central y Estad√≠stica har√° llegar a su correo su clave para acceder a la plataforma para intranet-alumnos y completar sus datos.\n",
      "    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad√≠stica enviar√° al correo del ingresante la ficha de datos. El llenado es car√°cter obligatorio.\n",
      "    4. Efectuar el pago por autoseguro dentro del plazo establecido en el cronograma de actividades academicas publicado en la pagina web de la Facultad de ciencias. Para ello, el ingresante debera generar una orden de pago atravez del portal INTRALU, luego podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria.\n",
      "    5. Realizar la entrega de los siguientes documentos a la oficina de estad√≠stica seg√∫n el cronograma de actividades de matr√≠cula de ingresantes publicado en la secci√≥n 'MATR√çCULA Y PROCEDIMIENTOS' en la p√°gina web de la Facultad de Ciencias.\n",
      "        - Contancia de Ingreso\n",
      "        - Ficha de datos Personales. Enviada por la oficina de estad√≠stica al correo del ingresante.\n",
      "        - Constancia de Evaluacion Socioeconomica. El ingresante debera acudir a la cita para su evaluacion socioeconomica que le llegara a su correo. \n",
      "        - Certificado M√©dico expedido por el Centro Medico UNI. Para ello acudir a su examen medico segun los cronograma publicados por la Direcci√≥n de Admisi√≥n. \n",
      "        - Comprobante de pago de Autoseguro Estudiantil\n",
      "    6. AERA ejecutar√° la matr√≠cula (inscripci√≥n de cursos) de los ingresantes seg√∫n el cronograma de actividades, √∫nicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\n",
      "    7. Los ingresantes matriculados recibir√°n un mensaje en su correo con el horario de sus cursos, ademas podran visualizar los cursos y horarios dentro del portal INTRALU.\n",
      "\n",
      "Para generar una orden de pago, el ingresante debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opci√≥n \"Tr√°mites\" para acceder al m√≥dulo de pagos. En dicho m√≥dulo, selecciona el tr√°mite correspondiente en el men√∫ desplegable, haz clic en el bot√≥n \"Nuevo\" y sigue las indicaciones hasta generar la orden de pago. Para mas detalles sobre el proceso para generar un orden de pogo puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\n",
      "\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto:\n",
      "Seg√∫n la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para F√≠sica, Qu√≠mica o Ciencia de la Computaci√≥n: escuelas_fc1@uni.edu.pe\n",
      "Para Matem√°ticas o Ingenier√≠a F√≠sica: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "√Årea de Estad√≠stica y Registros Acad√©micos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto de la oficina de estad√≠stica (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de la oficina de estad√≠stica (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "Si un alumno no cumpli√≥ con el pago del autoseguro, ¬øqu√© procedimiento debe seguir para gestionar su matr√≠cula rezagada?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Si un alumno no cumpli√≥ con el pago del autoseguro, no podr√° realizar la matr√≠cula rezagada. Para gestionar su matr√≠cula rezagada, primero debe realizar el pago del autoseguro m√©dico estudiantil. Luego, deber√° seguir estos pasos:\n",
      "\n",
      "1. Generar la orden de pago por concepto de matr√≠cula rezagada a trav√©s del portal INTRALU y realizar el pago correspondiente de S/ 26 en una agencia del BCP o mediante su banca m√≥vil.\n",
      "2. Presentarse en la Oficina de Estad√≠stica (AERA) en las fechas establecidas en el calendario de actividades acad√©micas, llevando el comprobante de pago.\n",
      "\n",
      "Recuerde que la matr√≠cula rezagada se realiza solo si se cumplen todos los requisitos y en las fechas establecidas.<|im_end|>\n",
      "<|im_start|>user\n",
      "¬øY si ya pagu√© el autoseguro, pero tengo dudas sobre c√≥mo generar la orden de pago en INTRALU? ¬øHay alg√∫n tutorial o gu√≠a que me recomiendes?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Para generar la orden de pago en INTRALU, debes acceder a la plataforma y seguir estos pasos:\n",
      "\n",
      "1. Selecciona la opci√≥n \"Tr√°mites\" para acceder al m√≥dulo de tr√°mites y pagos.\n",
      "2. En el m√≥dulo, elige \"PAGO-AUTOSEGURO MEDICO\" en el men√∫ desplegable.\n",
      "3. Haz clic en el bot√≥n \"Nuevo\" y sigue las indicaciones hasta generar la orden de pago por S/. 55.00.\n",
      "\n",
      "Para m√°s detalles sobre el proceso, puedes consultar el Manual de Pagos publicado en la secci√≥n \"MATR√çCULA Y PROCEDIMIENTOS\" en la p√°gina web de la Facultad de Ciencias. Si tienes m√°s dudas, no dudes en preguntar.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(trainer.train_dataset[1][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cf3a951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA RTX 4500 Ada Generation. Max memory = 23.994 GB.\n",
      "1.639 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46ed1bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 5,821 | Num Epochs = 1 | Total steps = 91\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 4 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 40,370,176/600,000,000 (6.73% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='91' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 31:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.264700</td>\n",
       "      <td>0.245399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but Qwen3ForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "/home/inictel-ivan/miniconda3/envs/llm/lib/python3.11/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "992d1a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0061, -0.0928,  0.0251,  ...,  0.0051, -0.0082, -0.0054],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "token_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>context\")\n",
    "print(model.get_input_embeddings().weight[token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e836a393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inictel-ivan/miniconda3/envs/llm/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/qwen3-finetuned-merge_and_unload/tokenizer_config.json',\n",
       " 'models/qwen3-finetuned-merge_and_unload/special_tokens_map.json',\n",
       " 'models/qwen3-finetuned-merge_and_unload/chat_template.jinja',\n",
       " 'models/qwen3-finetuned-merge_and_unload/vocab.json',\n",
       " 'models/qwen3-finetuned-merge_and_unload/merges.txt',\n",
       " 'models/qwen3-finetuned-merge_and_unload/added_tokens.json',\n",
       " 'models/qwen3-finetuned-merge_and_unload/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîÅ FUSIONAR EL MODELO\n",
    "model = model.merge_and_unload()  # Esto remueve LoRA y fusiona los pesos\n",
    "\n",
    "# ‚úÖ GUARDAR EL MODELO Y TOKENIZER\n",
    "model.save_pretrained(\"models/qwen3-finetuned-merge_and_unload\")\n",
    "tokenizer.save_pretrained(\"models/qwen3-finetuned-merge_and_unload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5f51e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA RTX 4500 Ada Generation. Num GPUs = 1. Max memory: 23.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name =  \"./models/qwen3-finetuned-merge_and_unload\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddd40416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}\n",
      "{% if message['role'] == 'system' %}\n",
      "<|im_start|>system\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'context' %}\n",
      "<|im_start|>context\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'user' %}\n",
      "<|im_start|>user\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'assistant' %}\n",
      "<|im_start|>assistant\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% endif %}\n",
      "{% endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "<|im_start|>assistant\n",
      "{%- if enable_thinking is defined and enable_thinking == false %}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{%- endif %}\n",
      "{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dda0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matr√≠cula, procedimientos y tr√°mites acad√©micos de la Facultad de Ciencias de la Universidad Nacional de Ingenier√≠a del Per√∫.\n",
      "Deber√°s responder a los mensajes asegur√°ndote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, √∫tiles y concisas a las preguntas del usuario bas√°ndote exclusivamente en el contexto proporcionado.\n",
      "    2. Mant√©n un tono cordial, emp√°tico y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina m√°s id√≥nea, la derivaci√≥n se realizar√° hacia la Oficina de Estad√≠stica (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empat√≠a que no tienes acceso a dicha informaci√≥n.<|im_end|>\n",
      "<|im_start|>context\n",
      "Generaci√≥n De Orden De Pago Para Autoseguro\n",
      "¬øCual es el proceso para que un ingresante o alumno regular genere una orden de pago para el pago de autoseguro?\n",
      "Para generar una orden de pago por concepto de autoseguro, el ingresante o alumno regular debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opci√≥n \"Tr√°mites\", para acceder al m√≥dulo de tramites y pagos. En dicho m√≥dulo, selecciona la opci√≥n \"PAGO-AUTOSEGURO MEDICO\" en el men√∫ desplegable, haz clic en el bot√≥n \"Nuevo\" y sigue las indicaciones hasta generar la orden de pago por el monto de S/. 55.00. Luego de generar la orden de pago el ingresante o estudiante regular podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria. Para mas detalles sobre el proceso para generar un orden de pago puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\n",
      "\n",
      "Fecha De Pago De Autoseguro\n",
      "¬øHasta que fecha se debe realizar el pago por concepto de autoseguro estudiantil para que un estudiante pueda realizar la matr√≠cula regular al ciclo academico en la Facultad de Ciencias de la UNI?\n",
      "Los estudiantes deben realizar el pago del autoseguro estudiantil antes de las fechas de matr√≠cula, dentro del plazo m√°ximo establecido en el calendario de actividades acad√©micas correspondiente al periodo acad√©mico. Si no se cumple con este plazo m√°ximo, no se habilitar√° en el sistema su matricula regular (inscripci√≥n de cursos) y deber√° gestionar la matricula como rezagada. El estudiante puede verificar esta situaci√≥n al comprobar si su matr√≠cula se habilita o no en las fechas de matr√≠cula regular. Si la matr√≠cula no se habilita en estas fechas, el estudiante podr√° solicitar su matricula rezagada. Sin embargo, la inscripci√≥n de cursos de la matricula rezagada se realiza en funci√≥n de las vacantes disponibles por lo que se corre el riesgo de no alcanzar vacantes para los cursos deseados.\n",
      "El calendario de actividades acad√©micas es publicado en la secci√≥n \"MATR√çCULA Y PROCEDIMIENTOS\" de la pagina web de la Facultad de Ciencias, puede acceder a esta secci√≥n de la web mediante el siguiente enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Requisitos Y Procedimiento De Matricula Para Estudiantes Regulares\n",
      "¬øCuales son los requisitos y el proceso de matr√≠cula regular al ciclo acad√©mico para alumnos regulares de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier√≠a?\n",
      "Los estudiantes regulares de pregrado en la Facultad de Ciencias de la UNI deben cumplir con siguientes requisitos y procedimiento para realizar su matr√≠cula al ciclo acad√©mico.\n",
      "\n",
      "Requisitos para la matricula:\n",
      "1. Haber efectuado el pago del autoseguro estudiantil mediante la plataforma intranet-alumnos.\n",
      "\n",
      "2. No tener adeudos pendientes con la Facultad, ya sea por concepto econ√≥mico, pr√©stamos de libros u otros materiales de ense√±anza en general de la biblioteca.\n",
      "\n",
      "3. En caso de estar en riesgo acad√©mico, haber completado la tutor√≠a obligatoria previa a la matr√≠cula.\n",
      "\n",
      "4. Si el estudiante ha dejado de estudiar, reservado matr√≠cula o solicitado retiro total en el √∫ltimo per√≠odo, deber√° tramitar previamente su reincorporaci√≥n a trav√©s de la plataforma intranet-alumnos.\n",
      "\n",
      "Procedimiento para la matr√≠cula regular:\n",
      "1. Generar la orden de pago del autoseguro estudiantil a trav√©s de la plataforma INTRALU. Para ello, haz clic en \"Tr√°mites\" para acceder al m√≥dulo de tr√°mites y pagos. Luego, selecciona el tr√°mite correspondiente, haz clic en \"Nuevo\" y sigue las instrucciones para completar el proceso.\n",
      "2. Realizar el pago del autoseguro dentro del plazo establecido en el calendario de actividades acad√©micas, acerc√°ndose a un sucursal del BCP o a traves de la aplicaci√≥n movil del banco. No se requiere la entrega del voucher de pago del autoseguro ni otros documentos.\n",
      "3. En la fecha y turno asignado, el estudiante llevar√° a cabo a su matr√≠cula de forma virtual, es decir, realizar√° la inscripci√≥n de sus cursos a trav√©s de la plataforma intranet-alumnos. Acceder√° al m√≥dulo de Matr√≠cula UNI dentro de esta plataforma, seleccionar√° las asignaturas y horarios deseados, y finalizar√° confirmando la matr√≠cula en todas las asignaturas elegidas en el sistema.\n",
      "\n",
      "Los turnos de matr√≠cula se asignan por grupos seg√∫n el promedio ponderado de los dos √∫ltimos ciclos acad√©micos, en orden de m√©rito. Los estudiantes pueden consultarlos en el m√≥dulo de Matr√≠cula UNI de la intranet-alumnos.\n",
      "\n",
      "Procedimiento General Para Generar Una Orden De Pago\n",
      "¬øCu√°l es el procedimiento que debe seguir un estudiante para generar una orden de pago relacionada con alg√∫n concepto o tr√°mite espec√≠fico y realizar el pago correspondiente?\n",
      "Para generar una orden, el estudiante debe seguir los siguientes pasos:\n",
      "    1. Acceder a la plataforma INTRALU.\n",
      "    2. Dentro de la plataforma, seleccionar la opci√≥n \"Tr√°mites\" para acceder al m√≥dulo de tramites y pagos.\n",
      "    3. En el m√≥dulo de pagos, selecciona el tr√°mite correspondiente en el men√∫ desplegable. Despu√©s, haz clic en el bot√≥n \"Nuevo\" y siga las indicaciones hasta generar la orden de pago correspondiente.\n",
      "\n",
      "Para cualquier otro tr√°mite que no est√© estipulado en la lista de opciones dentro de la plataforma, solicitar la generaci√≥n de la orden de pago a la oficina de estad√≠stica (AERA) al correo estadistica_fc@uni.edu.pe, detallando el concepto del tramite y sus datos personales (DNI, apellidos, nombres, correo institucional) en el mensaje.\n",
      "\n",
      "Una vez generada la orden de pago, el alumno deber√° esperar aproximadamente 10 minutos para realizar el pago correspondiente en una sucursal del BCP o a trav√©s de la aplicaci√≥n m√≥vil del banco.\n",
      "\n",
      "Para obtener m√°s detalles sobre el proceso para generar una orden de pago a traves de la plataforma, consulta el Manual de Pagos publicado dentro de la secci√≥n de \"MATR√çCULA Y PROCEDIMIENTOS\" en la P√°gina Web de la Facultad de Ciencias, puede ingresar a dicha secci√≥n a traves del enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Proceso De Pago De Una Orden De Pago\n",
      "¬øComo pagar una orden de pago generada por el alg√∫n concepto o tramite?\n",
      "Los ingresantes o estudiantes de la Universidad Nacional de Ingenier√≠a, luego de generar una orden de pago por alg√∫n concepto o tr√°mite, pueden realizar el pago en alguna sucursal del BCP o a trav√©s de la aplicaci√≥n m√≥vil del banco. En la app, deben seleccionar \"Pagar servicios\", buscar a la Universidad Nacional de Ingenier√≠a y seleccionarla, luego elegir la opci√≥n de pago para estudiantes e ingresar su n√∫mero de DNI. La aplicaci√≥n mostrar√° la orden de pago con el monto exacto para realizar el pago.\n",
      "Se recomienda esperar al menos 10 minutos luego de generar la orden para realizar el pago correspondiente.\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto:\n",
      "Seg√∫n la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para F√≠sica, Qu√≠mica o Ciencia de la Computaci√≥n: escuelas_fc1@uni.edu.pe\n",
      "Para Matem√°ticas o Ingenier√≠a F√≠sica: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "√Årea de Estad√≠stica y Registros Acad√©micos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto de la oficina de estad√≠stica (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de la oficina de estad√≠stica (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "¬øQu√© m√©todos de pago pueden usar los estudiantes para su orden de pago de autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Okay, the user is asking about the payment methods available for students to pay their order of payment for university insurance. Let me start by recalling the context provided.\n",
      "\n",
      "In the initial message, it was about generating a payment for insurance, and the steps mentioned were using the intranet platform. The user then asked about the payment methods, so I need to check the information given. \n",
      "\n",
      "Looking back, the initial instructions said to use the intranet platform. The answer provided included steps like selecting \"Tr√°mites\" and then \"PAGO-AUTOSEGURO MEDICO\", and the payment was done via BCP app or bank transfer. \n",
      "\n",
      "The user might be looking for a list of methods besides the BCP app. The original response mentioned \"en alguna sucursal del BCP o en alguna sucursal de la entidad bancaria\", which implies bank transfers. But the user might also want to know about other options. \n",
      "\n",
      "Wait, the context says \"PAGO-AUTOSEGURO MEDICO\" in the menu, and the payment was done through the BCP app. The next step is to use the app, so maybe the payment method is the app. However, the user is asking for all methods, not just the app. The original answer didn't mention other options. \n",
      "\n",
      "I need to confirm that the available methods are the BCP app and bank transfer. The user might be looking for a list. So the answer should state that the methods include the BCP app and bank transfer, as mentioned. Also, mention that the payment is done via the app once the order is generated. Make sure to avoid any additional information beyond that.\n",
      "</think>\n",
      "\n",
      "Los m√©todos de pago para realizar el pago del autoseguro estudiantil incluyen:  \n",
      "1. **Pago por aplicaci√≥n m√≥vil del Banco**: El estudiante puede realizar el pago mediante el m√≥vil del banco, seleccionando \"Pagar servicios\" y ingresando su DNI.  \n",
      "2. **Sucursal del BCP**: El pago se realiza en una sucursal del BCP o en una aplicaci√≥n m√≥vil del banco.  \n",
      "\n",
      "El proceso implica generar la orden de pago a trav√©s de la plataforma INTRALU y confirmar el pago en una sucursal bancaria. No hay otras opciones mencionadas en el contexto proporcionado.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from transformers import TextStreamer\n",
    "\n",
    "dtype = None\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "\n",
    "messages = dataset['train'][3]['turns'][:-1]\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs , \n",
    "    max_new_tokens = 500, \n",
    "    use_cache = True, \n",
    "    streamer = streamer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"models/qwen3-finetuned-merged\", torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"models/qwen3-finetuned-merged\")\n",
    "print(tokenizer.get_vocab().get(\"<|im_start|>context\"))  # Deber√≠a imprimir un ID, no None\n",
    "print(tokenizer.get_vocab().get(\"<|context|>\"))\n",
    "model.save_pretrained(\"models/qwen3-finetuned\")\n",
    "tokenizer.save_pretrained(\"models/qwen3-finetuned\")\n",
    "model.save_pretrained_merged(\"models/qwen3-finetuned-16bit\", tokenizer, save_method = \"merged_16bit\",)\n",
    "model.save_pretrained_merged(\"models/qwen3-finetuned-4bit\", tokenizer, save_method = \"merged_4bit_forced\",)\n",
    "model.save_pretrained_merged(\"models/qwen3-finetuned-merged\", tokenizer)\n",
    "model.save_pretrained_merged(\"models/qwen3-finetuned-merged\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46b024d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Eres Aerito, un asistente de IA especializado en temas de matr√≠cula, procedimientos y tr√°mites acad√©micos de la Facultad de Ciencias de la Universidad Nacional de Ingenier√≠a del Per√∫.\\nDeber√°s responder a los mensajes asegur√°ndote de cumplir con los siguientes criterios.\\n    1. Proporcionar respuestas informativas, √∫tiles y concisas a las preguntas del usuario bas√°ndote exclusivamente en el contexto proporcionado.\\n    2. Mant√©n un tono cordial, emp√°tico y servicial en sus interacciones.\\n    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina m√°s id√≥nea, la derivaci√≥n se realizar√° hacia la Oficina de Estad√≠stica (AERA) de la Facultad de Ciencias.\\n    4. En caso de no tener conocimiento sobre lo consultado, expresa con empat√≠a que no tienes acceso a dicha informaci√≥n.',\n",
       "  'role': 'system'},\n",
       " {'content': 'Fecha De Pago De Autoseguro\\n¬øHasta que fecha se debe realizar el pago por concepto de autoseguro estudiantil para que un estudiante pueda realizar la matr√≠cula regular al ciclo academico en la Facultad de Ciencias de la UNI?\\nLos estudiantes deben realizar el pago del autoseguro estudiantil antes de las fechas de matr√≠cula, dentro del plazo m√°ximo establecido en el calendario de actividades acad√©micas correspondiente al periodo acad√©mico. Si no se cumple con este plazo m√°ximo, no se habilitar√° en el sistema su matricula regular (inscripci√≥n de cursos) y deber√° gestionar la matricula como rezagada. El estudiante puede verificar esta situaci√≥n al comprobar si su matr√≠cula se habilita o no en las fechas de matr√≠cula regular. Si la matr√≠cula no se habilita en estas fechas, el estudiante podr√° solicitar su matricula rezagada. Sin embargo, la inscripci√≥n de cursos de la matricula rezagada se realiza en funci√≥n de las vacantes disponibles por lo que se corre el riesgo de no alcanzar vacantes para los cursos deseados.\\nEl calendario de actividades acad√©micas es publicado en la secci√≥n \"MATR√çCULA Y PROCEDIMIENTOS\" de la pagina web de la Facultad de Ciencias, puede acceder a esta secci√≥n de la web mediante el siguiente enlace: https://fc.uni.edu.pe/estadistica/documentos/\\n\\nEscuelas Profesionales de la Facultad de Ciencias de la UNI\\n\\nInformaci√≥n de Contacto:\\nSeg√∫n la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\\n\\nPara F√≠sica, Qu√≠mica o Ciencia de la Computaci√≥n: escuelas_fc1@uni.edu.pe\\nPara Matem√°ticas o Ingenier√≠a F√≠sica: escuelas_fc2@uni.edu.pe\\n\\nHorario de Atenci√≥n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\\n\\n√Årea de Estad√≠stica y Registros Acad√©micos de la Facultad de Ciencias de la UNI\\n\\nInformaci√≥n de Contacto de la oficina de estad√≠stica (AERA)\\nE-mail: estadistica_fc@uni.edu.pe\\n\\nHorario de Atenci√≥n de la oficina de estad√≠stica (AERA):\\nDe Lunes a Viernes de 8:00 a.m. a 4:00 p.m.',\n",
       "  'role': 'context'},\n",
       " {'content': '¬øQu√© m√©todos de pago pueden usar los estudiantes para su orden de pago de autoseguro?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Los estudiantes pueden realizar el pago de la orden de pago por concepto de autoseguro a trav√©s de dos m√©todos: en alguna sucursal del BCP o mediante la aplicaci√≥n m√≥vil del banco BCP. Se recomienda esperar al menos 10 minutos despu√©s de generar la orden de pago antes de proceder con el pago. Si necesitas m√°s informaci√≥n, no dudes en preguntar.',\n",
       "  'role': 'assistant'},\n",
       " {'content': '¬øY qu√© pasa si no tengo cuenta en el BCP? ¬øHay otras opciones para pagar el autoseguro?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Lamentablemente, solo se menciona el pago del autoseguro a trav√©s de sucursales del BCP o mediante la aplicaci√≥n m√≥vil del mismo banco. No tengo acceso a informaci√≥n sobre otras opciones de pago disponibles. Te sugiero que contactes a la Oficina de Estad√≠stica de la Facultad de Ciencias para obtener m√°s detalles sobre posibles alternativas. Su correo es estadistica_fc@uni.edu.pe y su horario de atenci√≥n es de lunes a viernes de 8:00 a.m. a 4:00 p.m. Si necesitas m√°s ayuda, no dudes en preguntar.',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Entendido. Voy a contactar a la Oficina de Estad√≠stica para ver si tienen m√°s opciones. ¬øSabes si hay alg√∫n plazo espec√≠fico para hacer el pago del autoseguro?',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b052bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matr√≠cula, procedimientos y tr√°mites acad√©micos de la Facultad de Ciencias de la Universidad Nacional de Ingenier√≠a del Per√∫.\n",
      "Deber√°s responder a los mensajes asegur√°ndote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, √∫tiles y concisas a las preguntas del usuario bas√°ndote exclusivamente en el contexto proporcionado.\n",
      "    2. Mant√©n un tono cordial, emp√°tico y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina m√°s id√≥nea, la derivaci√≥n se realizar√° hacia la Oficina de Estad√≠stica (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empat√≠a que no tienes acceso a dicha informaci√≥n.<|im_end|>\n",
      "<|im_start|>context\n",
      "Fecha De Pago De Autoseguro\n",
      "¬øHasta que fecha se debe realizar el pago por concepto de autoseguro estudiantil para que un estudiante pueda realizar la matr√≠cula regular al ciclo academico en la Facultad de Ciencias de la UNI?\n",
      "Los estudiantes deben realizar el pago del autoseguro estudiantil antes de las fechas de matr√≠cula, dentro del plazo m√°ximo establecido en el calendario de actividades acad√©micas correspondiente al periodo acad√©mico. Si no se cumple con este plazo m√°ximo, no se habilitar√° en el sistema su matricula regular (inscripci√≥n de cursos) y deber√° gestionar la matricula como rezagada. El estudiante puede verificar esta situaci√≥n al comprobar si su matr√≠cula se habilita o no en las fechas de matr√≠cula regular. Si la matr√≠cula no se habilita en estas fechas, el estudiante podr√° solicitar su matricula rezagada. Sin embargo, la inscripci√≥n de cursos de la matricula rezagada se realiza en funci√≥n de las vacantes disponibles por lo que se corre el riesgo de no alcanzar vacantes para los cursos deseados.\n",
      "El calendario de actividades acad√©micas es publicado en la secci√≥n \"MATR√çCULA Y PROCEDIMIENTOS\" de la pagina web de la Facultad de Ciencias, puede acceder a esta secci√≥n de la web mediante el siguiente enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto:\n",
      "Seg√∫n la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para F√≠sica, Qu√≠mica o Ciencia de la Computaci√≥n: escuelas_fc1@uni.edu.pe\n",
      "Para Matem√°ticas o Ingenier√≠a F√≠sica: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "√Årea de Estad√≠stica y Registros Acad√©micos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Informaci√≥n de Contacto de la oficina de estad√≠stica (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atenci√≥n de la oficina de estad√≠stica (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "¬øQu√© m√©todos de pago pueden usar los estudiantes para su orden de pago de autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Los estudiantes pueden realizar el pago de la orden de pago por concepto de autoseguro a trav√©s de dos m√©todos: en alguna sucursal del BCP o mediante la aplicaci√≥n m√≥vil del banco BCP. Se recomienda esperar al menos 10 minutos despu√©s de generar la orden de pago antes de proceder con el pago. Si necesitas m√°s informaci√≥n, no dudes en preguntar.<|im_end|>\n",
      "<|im_start|>user\n",
      "¬øY qu√© pasa si no tengo cuenta en el BCP? ¬øHay otras opciones para pagar el autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Lamentablemente, solo se menciona el pago del autoseguro a trav√©s de sucursales del BCP o mediante la aplicaci√≥n m√≥vil del mismo banco. No tengo acceso a informaci√≥n sobre otras opciones de pago disponibles. Te sugiero que contactes a la Oficina de Estad√≠stica de la Facultad de Ciencias para obtener m√°s detalles sobre posibles alternativas. Su correo es estadistica_fc@uni.edu.pe y su horario de atenci√≥n es de lunes a viernes de 8:00 a.m. a 4:00 p.m. Si necesitas m√°s ayuda, no dudes en preguntar.<|im_end|>\n",
      "<|im_start|>user\n",
      "Entendido. Voy a contactar a la Oficina de Estad√≠stica para ver si tienen m√°s opciones. ¬øSabes si hay alg√∫n plazo espec√≠fico para hacer el pago del autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked about specific payment deadlines for university students regarding student health insurance. I need to check if there's a specific date when they must pay this insurance for the semester.\n",
      "\n",
      "First, I should look up the information from the provided context. In the given information, it mentions that students must pay the insurance before the enrollment dates, and if they don't, they can reschedule. The dates for payment and rescheduling are mentioned as the maximum allowed period, so there is no "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     15\u001b[39m streamer = TextStreamer(tokenizer)\n\u001b[32m     17\u001b[39m inputs = tokenizer.apply_chat_template(\n\u001b[32m     18\u001b[39m     messages,\n\u001b[32m     19\u001b[39m     tokenize = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     20\u001b[39m     add_generation_prompt = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     21\u001b[39m     return_tensors = \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m ).to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m#print(tokenizer.batch_decode(outputs)[0])\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1634\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1632\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1638\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1639\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1640\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:3560\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3560\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3562\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3563\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3564\u001b[39m     outputs,\n\u001b[32m   3565\u001b[39m     model_kwargs,\n\u001b[32m   3566\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1086\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_CausalLM_fast_forward\u001b[39m(\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1070\u001b[39m     input_ids: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1083\u001b[39m     *args, **kwargs,\n\u001b[32m   1084\u001b[39m ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[32m   1085\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1086\u001b[39m         outputs = \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1094\u001b[39m         causal_mask = xformers.attn_bias.LowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1019\u001b[39m, in \u001b[36m_LlamaModel_fast_forward_inference.<locals>.LlamaModel_fast_forward_inference_custom\u001b[39m\u001b[34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[39m\n\u001b[32m   1011\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[32m   1012\u001b[39m X = fast_rms_layernorm_inference(\n\u001b[32m   1013\u001b[39m     decoder_layer.input_layernorm,\n\u001b[32m   1014\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1017\u001b[39m     variance = variance,\n\u001b[32m   1018\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m X, present_key_value = \u001b[43mattention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpaged_attention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m X += residual\n\u001b[32m   1029\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/qwen3.py:283\u001b[39m, in \u001b[36mQwen3Attention_fast_forward_inference\u001b[39m\u001b[34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[39m\n\u001b[32m    281\u001b[39m Qn = fast_linear_forward(\u001b[38;5;28mself\u001b[39m.q_proj, Xn, out = \u001b[38;5;28mself\u001b[39m.temp_QA[\u001b[32m0\u001b[39m])\n\u001b[32m    282\u001b[39m Kn = fast_linear_forward(\u001b[38;5;28mself\u001b[39m.k_proj, Xn, out = \u001b[38;5;28mself\u001b[39m.temp_KV[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m Vn = \u001b[43mfast_linear_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv_proj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemp_KV\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m Qn = Qn.view(bsz, \u001b[32m1\u001b[39m, n_heads,    head_dim)\u001b[38;5;66;03m#.transpose(1, 2) # we will transpose after normalisation\u001b[39;00m\n\u001b[32m    285\u001b[39m Kn = Kn.view(bsz, \u001b[32m1\u001b[39m, n_kv_heads, head_dim)\u001b[38;5;66;03m#.transpose(1, 2) # we will transpose after normalisation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/kernels/utils.py:440\u001b[39m, in \u001b[36mfast_linear_forward\u001b[39m\u001b[34m(proj, X, temp_lora, out)\u001b[39m\n\u001b[32m    438\u001b[39m     out = torch_matmul(X, W.t(), out = out)\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m bsz == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_len == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     out = \u001b[43mfast_gemv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    442\u001b[39m     W = fast_dequantize(W.t(), W_quant, use_global_buffer = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/kernels/utils.py:346\u001b[39m, in \u001b[36mfast_gemv\u001b[39m\u001b[34m(X, W, quant_state, out)\u001b[39m\n\u001b[32m    344\u001b[39m df = torch_empty(absmax.shape, dtype = torch.float32, device = device)\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch_cuda_device(device):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[43mcdequantize_blockwise_fp32\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsmax2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes_c_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocksize2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes_c_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCUDA_STREAM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     df += offset\n\u001b[32m    351\u001b[39m     absmax = df\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from transformers import TextStreamer\n",
    "\n",
    "#tokenizer = get_chat_template(\n",
    "#    tokenizer,\n",
    "#    chat_template = \"qwen-2.5\",\n",
    "#)\n",
    "\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "\n",
    "messages = dataset['train'][5]['turns'][:-1]\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs , \n",
    "    max_new_tokens = 256, \n",
    "    use_cache = True, \n",
    "    streamer = streamer,\n",
    "    temperature = 1.5, \n",
    "    min_p = 0.1)\n",
    "\n",
    "\n",
    "#print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4845767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparate Conversations:   0%|          | 0/1919 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparate Conversations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1919/1919 [00:00<00:00, 3310.07it/s]\n",
      "Batching:   0%|          | 0/160 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "!handles_.at(i) INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":396, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     38\u001b[39m tokenized = tokenizer(\n\u001b[32m     39\u001b[39m     batch_inputs,\n\u001b[32m     40\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m     padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     42\u001b[39m     truncation=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     43\u001b[39m ).to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Decodificar solo lo nuevo generado por cada ejemplo\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1634\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1632\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1638\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1639\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1640\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:3557\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3554\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3557\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1103\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28mself\u001b[39m.model._has_no_labels = labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1116\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:924\u001b[39m, in \u001b[36mLlamaModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    921\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:592\u001b[39m, in \u001b[36mLlamaDecoderLayer_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m residual = hidden_states\n\u001b[32m    591\u001b[39m hidden_states = fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m.input_layernorm, hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    605\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/qwen3.py:187\u001b[39m, in \u001b[36mQwen3Attention_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m Q, K, V = Q.contiguous(), K.contiguous(), V.contiguous()\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# Needs (batch_size, n_heads, seq_len, head_dim)\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# is_casual and attention_mask must not be both set!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m A = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Go back to (batch_size, seq_len, n_heads, head_dim)\u001b[39;00m\n\u001b[32m    189\u001b[39m A = A.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n",
      "\u001b[31mRuntimeError\u001b[39m: !handles_.at(i) INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":396, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "generation_outputs = dict(messages = [], pred_outputs = [], true_outputs = [])\n",
    "\n",
    "val_dataset = dataset['val']\n",
    "\n",
    "# Preparamos las entradas (messages + labels separados)\n",
    "inputs_list = []\n",
    "true_outputs = []\n",
    "messages_list = []\n",
    "\n",
    "tokenizer.padding_side = \"left\"  # importante para generaci√≥n\n",
    "\n",
    "for conv in tqdm(val_dataset,desc = \"Preparate Conversations\"):\n",
    "    messages = conv['turns'][:-1]\n",
    "    messages_list.append(messages)\n",
    "    input = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    inputs_list.append(input)\n",
    "    true_outputs.append(conv['turns'][-1][\"content\"])\n",
    "\n",
    "# Procesamos por batch\n",
    "batch_size = 12\n",
    "\n",
    "for i in tqdm(range(0, len(inputs_list), batch_size), desc=\"Batching\"):\n",
    "    batch_inputs = inputs_list[i:i+batch_size]\n",
    "    batch_truths = true_outputs[i:i+batch_size]\n",
    "    batch_messages = messages_list[i:i+batch_size]\n",
    "\n",
    "    # Tokenizar y padear batch\n",
    "    tokenized = tokenizer(\n",
    "        batch_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=tokenized[\"input_ids\"],\n",
    "            attention_mask=tokenized[\"attention_mask\"],\n",
    "            max_new_tokens=256,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    # Decodificar solo lo nuevo generado por cada ejemplo\n",
    "    for j in range(len(outputs)):\n",
    "        input_len = tokenized[\"input_ids\"][j].shape[0]\n",
    "        generated_tokens = outputs[j][input_len:]\n",
    "        generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "        generation_outputs[\"messages\"].append(batch_messages[j])\n",
    "        generation_outputs[\"pred_outputs\"].append(generated_text)\n",
    "        generation_outputs[\"true_outputs\"].append(batch_truths[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14591eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>pred_outputs</th>\n",
       "      <th>true_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>El Manual de Pagos est√° disponible en la secci...</td>\n",
       "      <td>El Manual de Pagos est√° disponible en la secci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>No hay un plazo espec√≠fico mencionado para gen...</td>\n",
       "      <td>No hay un plazo espec√≠fico mencionado para gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>S√≠, puedes consultar el estado de tu matr√≠cula...</td>\n",
       "      <td>S√≠, puedes consultar el estado de tu matr√≠cula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>Algunos estudiantes pueden enfrentar problemas...</td>\n",
       "      <td>Los problemas comunes que los estudiantes suel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>S√≠, puedes contactar a la Oficina de Estad√≠sti...</td>\n",
       "      <td>La Oficina de Estad√≠stica (AERA) de la Faculta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>¬°De nada! Me alegra haber podido ayudarte. Si ...</td>\n",
       "      <td>¬°De nada! Me alegra haber podido ayudarte. Si ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>Para fijar el l√≠mite de cr√©ditos para estudian...</td>\n",
       "      <td>El l√≠mite de cr√©ditos para estudiantes que han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>La Tabla 1 del Reglamento de Matr√≠cula est√° di...</td>\n",
       "      <td>La Tabla 1 del Reglamento de Matr√≠cula est√° di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "1  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "2  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "3  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "4  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "5  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "6  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "7  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "\n",
       "                                        pred_outputs  \\\n",
       "0  El Manual de Pagos est√° disponible en la secci...   \n",
       "1  No hay un plazo espec√≠fico mencionado para gen...   \n",
       "2  S√≠, puedes consultar el estado de tu matr√≠cula...   \n",
       "3  Algunos estudiantes pueden enfrentar problemas...   \n",
       "4  S√≠, puedes contactar a la Oficina de Estad√≠sti...   \n",
       "5  ¬°De nada! Me alegra haber podido ayudarte. Si ...   \n",
       "6  Para fijar el l√≠mite de cr√©ditos para estudian...   \n",
       "7  La Tabla 1 del Reglamento de Matr√≠cula est√° di...   \n",
       "\n",
       "                                        true_outputs  \n",
       "0  El Manual de Pagos est√° disponible en la secci...  \n",
       "1  No hay un plazo espec√≠fico mencionado para gen...  \n",
       "2  S√≠, puedes consultar el estado de tu matr√≠cula...  \n",
       "3  Los problemas comunes que los estudiantes suel...  \n",
       "4  La Oficina de Estad√≠stica (AERA) de la Faculta...  \n",
       "5  ¬°De nada! Me alegra haber podido ayudarte. Si ...  \n",
       "6  El l√≠mite de cr√©ditos para estudiantes que han...  \n",
       "7  La Tabla 1 del Reglamento de Matr√≠cula est√° di...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(generation_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:   0%|          | 0/1919 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k', 'cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Conversations:   0%|          | 0/1919 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     15\u001b[39m generation_outputs[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m].append(messages)\n\u001b[32m     17\u001b[39m inputs = tokenizer.apply_chat_template(\n\u001b[32m     18\u001b[39m     messages,\n\u001b[32m     19\u001b[39m     tokenize = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     20\u001b[39m     add_generation_prompt = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     21\u001b[39m     return_tensors = \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m text_output = tokenizer.decode(outputs[\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(inputs[\u001b[32m0\u001b[39m]):], skip_special_tokens = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     32\u001b[39m generation_outputs[\u001b[33m'\u001b[39m\u001b[33mpred_outputs\u001b[39m\u001b[33m'\u001b[39m].append(text_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1634\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1632\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1638\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1639\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1640\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:3557\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3554\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3557\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1103\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28mself\u001b[39m.model._has_no_labels = labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1116\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:708\u001b[39m, in \u001b[36mLlamaModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;66;03m# Embed positions\u001b[39;00m\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m inputs_embeds = inputs_embeds.to(_get_dtype(\u001b[38;5;28mself\u001b[39m.config.torch_dtype))\n\u001b[32m    712\u001b[39m \u001b[38;5;66;03m# Normalized from Gemma\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "generation_outputs = dict(messages = [], pred_outputs = [], true_outputs = [])\n",
    "\n",
    "val_dataset = dataset['val']\n",
    "\n",
    "for conv in tqdm(val_dataset, desc= \"Conversations\"):\n",
    "    messages = conv['turns'][:-1]\n",
    "    \n",
    "    generation_outputs['messages'].append(messages)\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = True,\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids = inputs , \n",
    "        max_new_tokens = 256, \n",
    "        use_cache = False, \n",
    "        temperature = 0.0,\n",
    "        do_sample = False)\n",
    "    \n",
    "    text_output = tokenizer.decode(outputs[0, len(inputs[0]):], skip_special_tokens = True)\n",
    "    generation_outputs['pred_outputs'].append(text_output)\n",
    "    generation_outputs['true_outputs'].append(conv['turns'][-1][\"content\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6312891b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>pred_outputs</th>\n",
       "      <th>true_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>El Manual de Pagos est√° disponible en la secci...</td>\n",
       "      <td>El Manual de Pagos est√° disponible en la secci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "\n",
       "                                        pred_outputs  \\\n",
       "0  El Manual de Pagos est√° disponible en la secci...   \n",
       "\n",
       "                                        true_outputs  \n",
       "0  El Manual de Pagos est√° disponible en la secci...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(generation_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5613b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from utils import save_json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "convs_sim_file = \"./conversational_faq/openline-questions/conv_sim_derived_questions_faq_33_0_to_7.json\"\n",
    "\n",
    "files = glob(\"./conversational_faq/openline-questions/*.json\")\n",
    "\n",
    "for file_path in tqdm(files, desc= \"File\"): \n",
    "    with open(file_path, \"r\") as f:\n",
    "        convs_data = json.load(f)\n",
    "\n",
    "    save_dir = \"./conversational_faq/openline-questions-fixed\"\n",
    "\n",
    "    convs_data_fix = convs_data.copy()\n",
    "\n",
    "    for turns_data in convs_data_fix:\n",
    "        for turn_data in turns_data[\"messages\"]:\n",
    "            if turn_data['role'] == \"user\":\n",
    "                context = turn_data['context']\n",
    "                recovered_texts = turn_data['recovered_texts']\n",
    "                max_idx = 0\n",
    "                \n",
    "                if recovered_texts is None:\n",
    "                    continue\n",
    "\n",
    "                for i, rt in enumerate(recovered_texts):\n",
    "                    if rt['text'] in context:\n",
    "                        max_idx = i\n",
    "                        #print(f\"{i}: encontrado\")\n",
    "                    #else:\n",
    "                        #print(f\"{i}: no encontrado\")\n",
    "\n",
    "                docs_range = [0, max_idx]\n",
    "                turn_data['docs_range'] = docs_range\n",
    "\n",
    "    base_name = os.path.basename(file_path)[:-5]\n",
    "    save_json(save_dir, base_name, convs_data_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "context =  \"\\n\\nRequisitos Y Procedimiento Para Matricula Solo Para Ingresantes\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula para nuevos ingresantes de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos nuevos estudiantes de pregrado ingresantes a la Facultad de Ciencias deber\\u00e1n seguir el siguiente proceso, por \\u00fanica vez, para completar su primera matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo la constancia de ingreso.\\n    2. Actualizaci\\u00f3n de datos en intranet. DIRCE har\\u00e1 llegar a su correo su clave para acceder a la plataforma de intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica de la facultad enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro (S/. 55.00) en el plazo establecido en el cronograma. Para ello, primero generar una orden de pago a traves de la plataforma intranet-alumnos.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula para ingresantes publicado dentro de la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Constancia de Ingreso\\n        - Ficha de datos\\n        - Constancia de Evaluaci\\u00f3n Socioecon\\u00f3mica\\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI\\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. La oficina de estad\\u00edstica ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un correo con el horario de sus cursos y tambi\\u00e9n podr\\u00e1n visualizar sus cursos y horarios en la plataforma intranet-alumnos.\\n\\nRequisitos Y Procedimiento De Matricula Para Estudiantes Regulares\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula regular al ciclo acad\\u00e9mico para alumnos regulares de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos estudiantes regulares de pregrado en la Facultad de Ciencias de la UNI deben cumplir con siguientes requisitos y procedimiento para realizar su matr\\u00edcula al ciclo acad\\u00e9mico.\\n\\nRequisitos para la matricula:\\n1. Haber efectuado el pago del autoseguro estudiantil mediante la plataforma intranet-alumnos.\\n\\n2. No tener adeudos pendientes con la Facultad, ya sea por concepto econ\\u00f3mico, pr\\u00e9stamos de libros u otros materiales de ense\\u00f1anza en general de la biblioteca.\\n\\n3. En caso de estar en riesgo acad\\u00e9mico, haber completado la tutor\\u00eda obligatoria previa a la matr\\u00edcula.\\n\\n4. Si el estudiante ha dejado de estudiar, reservado matr\\u00edcula o solicitado retiro total en el \\u00faltimo per\\u00edodo, deber\\u00e1 tramitar previamente su reincorporaci\\u00f3n a trav\\u00e9s de la plataforma intranet-alumnos.\\n\\nProcedimiento para la matr\\u00edcula regular:\\n1. Generar la orden de pago del autoseguro estudiantil a trav\\u00e9s de la plataforma INTRALU. Para ello, haz clic en \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de tr\\u00e1mites y pagos. Luego, selecciona el tr\\u00e1mite correspondiente, haz clic en \\\"Nuevo\\\" y sigue las instrucciones para completar el proceso.\\n2. Realizar el pago del autoseguro dentro del plazo establecido en el calendario de actividades acad\\u00e9micas, acerc\\u00e1ndose a un sucursal del BCP o a traves de la aplicaci\\u00f3n movil del banco. No se requiere la entrega del voucher de pago del autoseguro ni otros documentos.\\n3. En la fecha y turno asignado, el estudiante llevar\\u00e1 a cabo a su matr\\u00edcula de forma virtual, es decir, realizar\\u00e1 la inscripci\\u00f3n de sus cursos a trav\\u00e9s de la plataforma intranet-alumnos. Acceder\\u00e1 al m\\u00f3dulo de Matr\\u00edcula UNI dentro de esta plataforma, seleccionar\\u00e1 las asignaturas y horarios deseados, y finalizar\\u00e1 confirmando la matr\\u00edcula en todas las asignaturas elegidas en el sistema.\\n\\nLos turnos de matr\\u00edcula se asignan por grupos seg\\u00fan el promedio ponderado de los dos \\u00faltimos ciclos acad\\u00e9micos, en orden de m\\u00e9rito. Los estudiantes pueden consultarlos en el m\\u00f3dulo de Matr\\u00edcula UNI de la intranet-alumnos.\\n\\nMatricula Ingresantes\\nLos nuevos ingresantes a la Facultad de Ciencias de la Universidad Nacional de Ingenieria, deberan seguir realizar el siguiente proceso para completar su matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo electr\\u00f3nico la constancia de ingreso. Para m\\u00e1s detalles sobre el proceso, puede consultar con DIAD al correo informes.admision@uni.edu.pe. \\n    2. Actualizacion de datos en DIRCE. La Direcci\\u00f3n de Registros Central y Estad\\u00edstica har\\u00e1 llegar a su correo su clave para acceder a la plataforma para intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro dentro del plazo establecido en el cronograma de actividades academicas publicado en la pagina web de la Facultad de ciencias. Para ello, el ingresante debera generar una orden de pago atravez del portal INTRALU, luego podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula de ingresantes publicado en la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Contancia de Ingreso\\n        - Ficha de datos Personales. Enviada por la oficina de estad\\u00edstica al correo del ingresante.\\n        - Constancia de Evaluacion Socioeconomica. El ingresante debera acudir a la cita para su evaluacion socioeconomica que le llegara a su correo. \\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI. Para ello acudir a su examen medico segun los cronograma publicados por la Direcci\\u00f3n de Admisi\\u00f3n. \\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. AERA ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un mensaje en su correo con el horario de sus cursos, ademas podran visualizar los cursos y horarios dentro del portal INTRALU.\\n\\nPara generar una orden de pago, el ingresante debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opci\\u00f3n \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de pagos. En dicho m\\u00f3dulo, selecciona el tr\\u00e1mite correspondiente en el men\\u00fa desplegable, haz clic en el bot\\u00f3n \\\"Nuevo\\\" y sigue las indicaciones hasta generar la orden de pago. Para mas detalles sobre el proceso para generar un orden de pogo puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\\n\\n\\nTraslado Interno Procedimiento Y Requisitos\\n\\u00bfC\\u00f3mo es el procedimiento para que un estudiante de pregrado de la Facultad de Ciencias realice un traslado interno a otra carrera dentro de la misma Facultad?\\nPara llevar a cabo un traslado interno, un estudiante de la Facultad de Ciencias deber\\u00e1 seguir el siguiente procedimiento:\\n1. Realizar el pago correspondiente por concepto de primer o segundo traslado interno, seg\\u00fan sea el caso (S/ 125.20 o S/ 300.00). Para ello, el estudiante deber\\u00e1 generar una orden de pago a trav\\u00e9s de la plataforma INTRALU y efectuar el pago en una agencia del BCP o mediante el aplicativo m\\u00f3vil del banco.\\n2. El estudiante deber\\u00e1 presentar su solicitud a trav\\u00e9s de el plataforma intranet-alumnos, eligiendo la opci\\u00f3n \\\"Traslado Interno\\\" en el men\\u00fa \\\"Mis Tr\\u00e1mites\\\". Esta solicitud deber\\u00e1 ser enviada a traves de la plataforma en la fecha indicada en el calendario de actividades acad\\u00e9micas, adjuntando el comprobante de pago por concepto de traslado interno y la ficha acad\\u00e9mica.\\n3. La Escuela verificar\\u00e1 los documentos y requisitos propios dentro del primer d\\u00eda \\u00fatil de presentada la solicitud, registrar\\u00e1 el expediente y remitir\\u00e1 un correo de recepci\\u00f3n al interesado.\\n4. El director de Escuela o la Comisi\\u00f3n de Matr\\u00edcula analizar\\u00e1n las solicitudes y, utilizando el formato disponible en la web DIRCE, inscribir\\u00e1n las convalidaciones pertinentes seg\\u00fan el Avance Curricular del alumno, las notas y las normas de Convalidaci\\u00f3n.\\n5. Con la autorizaci\\u00f3n del director, el expediente ser\\u00e1 enviado al Decano y posteriormente presentado ante el Consejo de Facultad para su aprobaci\\u00f3n mediante Resoluci\\u00f3n Decanal y remisi\\u00f3n a la DIRCE.\\n6. La DIRCE ejecutar\\u00e1 el cambio de especialidad y realizar\\u00e1 las convalidaciones.\\n7. La Oficina de Estad\\u00edstica gestionar\\u00e1 la matr\\u00edcula de los estudiantes por traslado interno en funci\\u00f3n a la solicitud de matr\\u00edcula del director de la Escuela Profesional, y finalmente, la DIRCE realizar\\u00e1 la ejecuci\\u00f3n de la matr\\u00edcula en el sistema SIGA.\\n8. No se recibir\\u00e1n solicitudes extempor\\u00e1neas.\\nEscuelas Profesionales de la Facultad de Ciencias de la UNI\\n\\nInformaci\\u00f3n de Contacto:\\nSeg\\u00fan la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\\n\\nPara F\\u00edsica, Qu\\u00edmica o Ciencia de la Computaci\\u00f3n: escuelas_fc1@uni.edu.pe\\nPara Matem\\u00e1ticas o Ingenier\\u00eda F\\u00edsica: escuelas_fc2@uni.edu.pe\\n\\nHorario de Atenci\\u00f3n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\\n\\n\\u00c1rea de Estad\\u00edstica y Registros Acad\\u00e9micos de la Facultad de Ciencias de la UNI\\n\\nInformaci\\u00f3n de Contacto de la oficina de estad\\u00edstica (AERA)\\nE-mail: estadistica_fc@uni.edu.pe\\n\\nHorario de Atenci\\u00f3n de la oficina de estad\\u00edstica (AERA):\\nDe Lunes a Viernes de 8:00 a.m. a 4:00 p.m.\"\n",
    "recovered_texts = [\n",
    "                    {\n",
    "                        \"text\": \"Requisitos Y Procedimiento Para Matricula Solo Para Ingresantes\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula para nuevos ingresantes de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos nuevos estudiantes de pregrado ingresantes a la Facultad de Ciencias deber\\u00e1n seguir el siguiente proceso, por \\u00fanica vez, para completar su primera matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo la constancia de ingreso.\\n    2. Actualizaci\\u00f3n de datos en intranet. DIRCE har\\u00e1 llegar a su correo su clave para acceder a la plataforma de intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica de la facultad enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro (S/. 55.00) en el plazo establecido en el cronograma. Para ello, primero generar una orden de pago a traves de la plataforma intranet-alumnos.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula para ingresantes publicado dentro de la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Constancia de Ingreso\\n        - Ficha de datos\\n        - Constancia de Evaluaci\\u00f3n Socioecon\\u00f3mica\\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI\\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. La oficina de estad\\u00edstica ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un correo con el horario de sus cursos y tambi\\u00e9n podr\\u00e1n visualizar sus cursos y horarios en la plataforma intranet-alumnos.\",\n",
    "                        \"relatedness\": 0.7661936283111572\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Requisitos Y Procedimiento De Matricula Para Estudiantes Regulares\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula regular al ciclo acad\\u00e9mico para alumnos regulares de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos estudiantes regulares de pregrado en la Facultad de Ciencias de la UNI deben cumplir con siguientes requisitos y procedimiento para realizar su matr\\u00edcula al ciclo acad\\u00e9mico.\\n\\nRequisitos para la matricula:\\n1. Haber efectuado el pago del autoseguro estudiantil mediante la plataforma intranet-alumnos.\\n\\n2. No tener adeudos pendientes con la Facultad, ya sea por concepto econ\\u00f3mico, pr\\u00e9stamos de libros u otros materiales de ense\\u00f1anza en general de la biblioteca.\\n\\n3. En caso de estar en riesgo acad\\u00e9mico, haber completado la tutor\\u00eda obligatoria previa a la matr\\u00edcula.\\n\\n4. Si el estudiante ha dejado de estudiar, reservado matr\\u00edcula o solicitado retiro total en el \\u00faltimo per\\u00edodo, deber\\u00e1 tramitar previamente su reincorporaci\\u00f3n a trav\\u00e9s de la plataforma intranet-alumnos.\\n\\nProcedimiento para la matr\\u00edcula regular:\\n1. Generar la orden de pago del autoseguro estudiantil a trav\\u00e9s de la plataforma INTRALU. Para ello, haz clic en \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de tr\\u00e1mites y pagos. Luego, selecciona el tr\\u00e1mite correspondiente, haz clic en \\\"Nuevo\\\" y sigue las instrucciones para completar el proceso.\\n2. Realizar el pago del autoseguro dentro del plazo establecido en el calendario de actividades acad\\u00e9micas, acerc\\u00e1ndose a un sucursal del BCP o a traves de la aplicaci\\u00f3n movil del banco. No se requiere la entrega del voucher de pago del autoseguro ni otros documentos.\\n3. En la fecha y turno asignado, el estudiante llevar\\u00e1 a cabo a su matr\\u00edcula de forma virtual, es decir, realizar\\u00e1 la inscripci\\u00f3n de sus cursos a trav\\u00e9s de la plataforma intranet-alumnos. Acceder\\u00e1 al m\\u00f3dulo de Matr\\u00edcula UNI dentro de esta plataforma, seleccionar\\u00e1 las asignaturas y horarios deseados, y finalizar\\u00e1 confirmando la matr\\u00edcula en todas las asignaturas elegidas en el sistema.\\n\\nLos turnos de matr\\u00edcula se asignan por grupos seg\\u00fan el promedio ponderado de los dos \\u00faltimos ciclos acad\\u00e9micos, en orden de m\\u00e9rito. Los estudiantes pueden consultarlos en el m\\u00f3dulo de Matr\\u00edcula UNI de la intranet-alumnos.\",\n",
    "                        \"relatedness\": 0.649982213973999\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Matricula Ingresantes\\nLos nuevos ingresantes a la Facultad de Ciencias de la Universidad Nacional de Ingenieria, deberan seguir realizar el siguiente proceso para completar su matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo electr\\u00f3nico la constancia de ingreso. Para m\\u00e1s detalles sobre el proceso, puede consultar con DIAD al correo informes.admision@uni.edu.pe. \\n    2. Actualizacion de datos en DIRCE. La Direcci\\u00f3n de Registros Central y Estad\\u00edstica har\\u00e1 llegar a su correo su clave para acceder a la plataforma para intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro dentro del plazo establecido en el cronograma de actividades academicas publicado en la pagina web de la Facultad de ciencias. Para ello, el ingresante debera generar una orden de pago atravez del portal INTRALU, luego podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula de ingresantes publicado en la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Contancia de Ingreso\\n        - Ficha de datos Personales. Enviada por la oficina de estad\\u00edstica al correo del ingresante.\\n        - Constancia de Evaluacion Socioeconomica. El ingresante debera acudir a la cita para su evaluacion socioeconomica que le llegara a su correo. \\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI. Para ello acudir a su examen medico segun los cronograma publicados por la Direcci\\u00f3n de Admisi\\u00f3n. \\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. AERA ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un mensaje en su correo con el horario de sus cursos, ademas podran visualizar los cursos y horarios dentro del portal INTRALU.\\n\\nPara generar una orden de pago, el ingresante debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opci\\u00f3n \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de pagos. En dicho m\\u00f3dulo, selecciona el tr\\u00e1mite correspondiente en el men\\u00fa desplegable, haz clic en el bot\\u00f3n \\\"Nuevo\\\" y sigue las indicaciones hasta generar la orden de pago. Para mas detalles sobre el proceso para generar un orden de pogo puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\\n\",\n",
    "                        \"relatedness\": 0.6069541811943054\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Traslado Interno Procedimiento Y Requisitos\\n\\u00bfC\\u00f3mo es el procedimiento para que un estudiante de pregrado de la Facultad de Ciencias realice un traslado interno a otra carrera dentro de la misma Facultad?\\nPara llevar a cabo un traslado interno, un estudiante de la Facultad de Ciencias deber\\u00e1 seguir el siguiente procedimiento:\\n1. Realizar el pago correspondiente por concepto de primer o segundo traslado interno, seg\\u00fan sea el caso (S/ 125.20 o S/ 300.00). Para ello, el estudiante deber\\u00e1 generar una orden de pago a trav\\u00e9s de la plataforma INTRALU y efectuar el pago en una agencia del BCP o mediante el aplicativo m\\u00f3vil del banco.\\n2. El estudiante deber\\u00e1 presentar su solicitud a trav\\u00e9s de el plataforma intranet-alumnos, eligiendo la opci\\u00f3n \\\"Traslado Interno\\\" en el men\\u00fa \\\"Mis Tr\\u00e1mites\\\". Esta solicitud deber\\u00e1 ser enviada a traves de la plataforma en la fecha indicada en el calendario de actividades acad\\u00e9micas, adjuntando el comprobante de pago por concepto de traslado interno y la ficha acad\\u00e9mica.\\n3. La Escuela verificar\\u00e1 los documentos y requisitos propios dentro del primer d\\u00eda \\u00fatil de presentada la solicitud, registrar\\u00e1 el expediente y remitir\\u00e1 un correo de recepci\\u00f3n al interesado.\\n4. El director de Escuela o la Comisi\\u00f3n de Matr\\u00edcula analizar\\u00e1n las solicitudes y, utilizando el formato disponible en la web DIRCE, inscribir\\u00e1n las convalidaciones pertinentes seg\\u00fan el Avance Curricular del alumno, las notas y las normas de Convalidaci\\u00f3n.\\n5. Con la autorizaci\\u00f3n del director, el expediente ser\\u00e1 enviado al Decano y posteriormente presentado ante el Consejo de Facultad para su aprobaci\\u00f3n mediante Resoluci\\u00f3n Decanal y remisi\\u00f3n a la DIRCE.\\n6. La DIRCE ejecutar\\u00e1 el cambio de especialidad y realizar\\u00e1 las convalidaciones.\\n7. La Oficina de Estad\\u00edstica gestionar\\u00e1 la matr\\u00edcula de los estudiantes por traslado interno en funci\\u00f3n a la solicitud de matr\\u00edcula del director de la Escuela Profesional, y finalmente, la DIRCE realizar\\u00e1 la ejecuci\\u00f3n de la matr\\u00edcula en el sistema SIGA.\\n8. No se recibir\\u00e1n solicitudes extempor\\u00e1neas.\",\n",
    "                        \"relatedness\": 0.6002129912376404\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Procedimiento Para Solicitar Una Constancia De Matricula En La Facultad De Ciencias De La Uni\\n\\u00bfQu\\u00e9 procedimiento debe seguir un estudiante para solicitar una constancia de Matricula en ingles o en espa\\u00f1ol?\\nPara solicitar una constancia de matr\\u00edcula en ingl\\u00e9s o en espa\\u00f1ol, el estudiante deber seguir los siguientes pasos:\\n\\n1. Enviar un correo a estadistica_fc@uni.edu.pe solicitando una orden de pago para la CONSTANCIA DE MATR\\u00cdCULA. En el mensaje, deber\\u00e1 incluir sus datos personales: n\\u00famero de DNI, apellidos, nombres, correo institucional y/o alternativo.\\n\\n2. La oficina de estad\\u00edstica (AERA) le enviar\\u00e1 la orden de pago por el monto correspondiente al correo electr\\u00f3nico del estudiante.\\n\\n3. Realize el pago en alguna sucursal del BCP o a trav\\u00e9s aplicaci\\u00f3n movil del banco. En la app selecciona \\\"Pagar servicios\\\", elige la Universidad Nacional de Ingenier\\u00eda, luego la opci\\u00f3n de pago para estudiantes, e ingresa su n\\u00famero de DNI. La app mostrar\\u00e1 la orden de pago con el monto exacto para realizar el pago.\\n\\n4. Luego, deber\\u00e1 enviar la solicitud correspondiente a mesa de partes de la facultad de ciencias al correo mesadepartes_fc@uni.edu.pe. Es importante que se asegure de indicar en la solicitud si desea la CONSTANCIA DE MATR\\u00cdCULA en ingl\\u00e9s o espa\\u00f1ol. El modelo para esta solicitud est\\u00e1 disponible dentro de la secci\\u00f3n [\\\"MATR\\u00cdCULA Y PROCEDIMIENTOS\\\" en la p\\u00e1gina web de la Facultad de Ciencias](https://fc.uni.edu.pe/estadistica/documentos/).\\n\\n5. Por \\u00faltimo, la constancia se enviar\\u00e1 al correo institucional del estudiante.\",\n",
    "                        \"relatedness\": 0.5496701002120972\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Proceso De Matricula\\nDe los Requisitos de la Matr\\u00edcula\\nArt. 46\\u00b0 La ense\\u00f1anza en el antegrado es gratuita para la primera carrera profesional. Son requisitos para la matr\\u00edcula, los siguientes:\\n\\ta. Cumplir con los requisitos acad\\u00e9micos establecidos en el presente reglamento .\\n\\tb. Realizar el pago por concepto de Autoseguro M\\u00e9dico. En caso de inconvenientes, presentar por correo o de forma f\\u00edsica el recibo de pago.\\n\\tc. En caso de la matricula regular, reincorporaci\\u00f3n o traslado interno, no presentar adeudos con su Facultad (econ\\u00f3mico, libros, enseres, o material de ense\\u00f1anza en general)\\n\\td. Aquellos estudiantes que no puedan cumplir con las deudas del tipo econ\\u00f3mico podr\\u00e1n solicitar, con diez (1O) d\\u00edas \\u00fatiles de anticipaci\\u00f3n, facilidades a la Comisi\\u00f3n de Matr\\u00edcula y comprometerse a una forma de pago a plazos, evitando que sea una restricci\\u00f3n de su matr\\u00edcula. Esta ventaja se perder\\u00e1 si no hubiese cumplido con similar compromiso en su anterior matr\\u00edcula.\\n\\te. En el caso de los traslados internos, externos, graduados, titulados, convenios internacionales, adem\\u00e1s de los incisos anteriores, deben presentar la Constancia o la Resoluci\\u00f3n Directora! de convalidaci\\u00f3n de las asignaturas. \\n\\tf. Los estudiantes que realizan su matr\\u00edcula en forma rezagada deber\\u00e1n efectuar el pago correspondiente establecido en las normas de la UNI. \\n\\tg. Los estudiantes que hayan dejado de estudiar, o reservado matr\\u00edcula o hayan solicitado su retiro total en alg\\u00fan periodo anterior, deber\\u00e1n previamente haber solicitado su reincorporaci\\u00f3n ante su Decano y su tr\\u00e1mite lo realizar\\u00e1 v\\u00eda la plataforma DIRCE-UNI.\\n\\t\\t Si requiriesen cambio previo de Plan de Estudios y convalidaciones correspondientes, \\u00e9stas ya deben haberse tramitado. En estos casos , el tr\\u00e1mite de reincorporaci\\u00f3n debe hacerse con no menos de una semana adicional de anticipaci\\u00f3n.\\n\\th. El pago del carn\\u00e9 universitario no es requisito para la matr\\u00edcula.\\n\\ti. No ser\\u00e1 necesario que los estudiantes hayan participado en el \\u00faltimo proceso electoral para ser matriculados, sin que esto signifique exonerarlo de la multa correspondiente. \\n\\tj. Otros de acuerdo con lo establecido en las normas de la UNI.\",\n",
    "                        \"relatedness\": 0.5412235915660858\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Matricula Ingresantes\\n                MATR\\u00cdCULA DE INGRESANTES\\n(del Reglamento de Matr\\u00edcula Aprobado R.R. No0570 del 29.03.2022 y las modificacion de la Resoluci\\u00f3n Rectoral N\\u00b0 3084-2024-UNI)\\n\\nArt\\u00edculo 7\\u00b0: La matr\\u00edcula de ingresantes es el procedimiento a trav\\u00e9s del cual el ingresante acredita su condici\\u00f3n de estudiante al inscribirse en un periodo acad\\u00e9mico, en las fechas establecidas en el calendario de actividades acad\\u00e9micas seg\\u00fan la facultad que le corresponde, para matricularse no es obligatorio tomar el m\\u00e1ximo de cr\\u00e9ditos permitidos. La matr\\u00edcula implica el cumplimiento de la Ley Universitaria y es el resultado de un acto formal que es ejecutado personal y voluntariamente por el estudiante, sujeto a verificaci\\u00f3n posterior. Implica el cumplimiento de la Ley Universitaria, el Estatuto, las normas de la UNI y el presente reglamento.\\n\\n-----------------------------------------------------------------------------------------------------------------------------------------------\\n\\nProcedimiento de Matricula Para Ingresantes\",\n",
    "                        \"relatedness\": 0.531317925453186\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Procedimiento Para Solicitar El Correo Institucional\\n\\u00bfQu\\u00e9 procedimiento debe seguir un estudiante de la UNI para solicitar su correo institucional?\\nPara solicitar su correo institucional de la UNI, enviar un correo obtenercorreo@uni.pe proporcionando la siguiente informaci\\u00f3n:\\n    C\\u00f3digo de Alumno.\\n    Nombres y Apellidos.\\n    DNI.\\n    Especialidad.\\n    Indicar si es estudiante de pregrado o posgrado.\\n    Correo personal (que no sea @uni.pe ni @UNI.PE) donde se le enviar\\u00e1 la clave.\\n    N\\u00famero de Celular.\\n    Facultad.\",\n",
    "                        \"relatedness\": 0.5192470550537109\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Proceso De Matricula\\n\\tTodas las deudas pendientes del estudiante ser\\u00e1n exigidas al finalizar sus estudios e iniciar el tr\\u00e1mite para obtener de su grado de bachiller.\\n\\nDel Proceso de la Matr\\u00edcula Regular para Estudiantes de Antegrado\\n(del Reglamento de Matr\\u00edcula Aprobado R.R. No0570 del 29.03.2022)\\n\\nArt. 47\\u00b0 La matr\\u00edcula regular se realiza v\\u00eda internet a trav\\u00e9s del Sistema de Matr\\u00edcula UNI suministrado por DIRCE, en las fechas establecidas en el Calendario de Actividades de los Estudios de Antegrado de la UNI.\\nEste proceso es personal y se realizar puede desde cualquier equipo con acceso a internet y ser\\u00e1 bajo responsabilidad del estudiante, cumpliendo los siguientes pasos: \\n\\ta. Ingresar al Sistema de Matr\\u00edcula UNI seg\\u00fan el turno programado.\\n\\tb. En su Oferta de Matr\\u00edcula, seleccionar las asignaturas-secci\\u00f3n, comenzando por las obligatorias y de menor ciclo.\\n\\tc. Confirmar en el sistema la matr\\u00edcula en las asignaturas-secci\\u00f3n seleccionadas dentro del plazo establecido para dicho acto, consignando la secci\\u00f3n elegida.\\n\\td. El sistema presentar\\u00e1 el Reporte de Matr\\u00edcula del estudiante para su impresi\\u00f3n, remisi\\u00f3n , o archivo.\\n\\te. En caso de los estudiantes que est\\u00e1n en riesgo acad\\u00e9mico y de los que retornen de la suspensi\\u00f3n acad\\u00e9mica realizar\\u00e1n su matr\\u00edcula, seg\\u00fan lo coordinado con su respectivo tutor, quien autorizar\\u00e1 la activaci\\u00f3n de su c\\u00f3digo y supervisar\\u00e1 el respectivo Reporte.\",\n",
    "                        \"relatedness\": 0.4989213466644287\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Traslado Interno\\nDetalle del procedimiento de Traslado Interno: \\n    1. Realizar el pago correspondiente por concepto de primer o segundo traslado interno, seg\\u00fan sea el caso (S/ 125.20 o S/ 300.00). Para ello, el estudiante deber\\u00e1 generar una orden de pago a trav\\u00e9s de la plataforma INTRALU y efectuar el pago en una agencia del BCP o mediante el aplicativo m\\u00f3vil del banco.\\n    2. El interesado presentar\\u00e1 su solicitud a trav\\u00e9s del intranet alumnos / tramites; hasta la fecha que indica el calendario acad\\u00e9mico. Adjuntando lo siguiente: \\n        \\u2212 Comprobante de pago por el concepto de Traslado Interno. \\n        \\u2212 Ficha Acad\\u00e9mica \\n    3. La Escuela, dentro del 1er d\\u00eda \\u00fatil de presentada verificar\\u00e1 documentos y requisitos propios, registrar\\u00e1 el expediente y remitir\\u00e1 correo de recepci\\u00f3n al interesado. Luego, si fuere necesario, solicitar\\u00e1 a otras Escuelas Profesionales de la UNI la remisi\\u00f3n de s\\u00edlabos pertinentes, si el director lo solicita y atender\\u00e1 similares solicitudes de otras Escuelas  \\n    4. El director de Escuela o la Comisi\\u00f3n de Matr\\u00edcula analizar\\u00e1 las solicitudes y haciendo uso del formato disponible en la web DIRCE, inscribir\\u00e1 las convalidaciones pertinentes, seg\\u00fan el Avance Curricular del alumno, las notas y las normas de Convalidaci\\u00f3n. Si quedan notas no registradas, ser\\u00e1n motivo de convalidaci\\u00f3n posterior a la matr\\u00edcula.  \\n    5. Con  la  autorizaci\\u00f3n  del  director,  el  expediente  es  enviado  al  Decano  y  posteriormente presentarlo ante el Consejo de Facultad para su aprobaci\\u00f3n (mediante Resoluci\\u00f3n Decanal) y remisi\\u00f3n a la DIRCE.  \\n    6. La DIRCE ejecutar\\u00e1 el cambio de especialidad y/o facultad y las convalidaciones.   \\n    7. Registradas las convalidaciones, la Oficina de Estad\\u00edstica gestiona la matr\\u00edcula de los sestudiantes por traslado interno en funci\\u00f3n a la solicitud de matr\\u00edcula del director de la Escuela Profesional, finalmente la DIRCE realiza la ejecuci\\u00f3n de la matr\\u00edcula en el sistema SIGA. \\n    8. No se recibir\\u00e1n solicitudes extempor\\u00e1neas \",\n",
    "                        \"relatedness\": 0.4829025506973267\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "print(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
