{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faf9dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA RTX 4500 Ada Generation. Num GPUs = 1. Max memory: 23.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bf16_supported\n",
    "import torch\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "max_seq_length = 4096\n",
    "lora_rank = 64\n",
    "dtype = None\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name =  \"./models/unsloth-Qwen3-0.6B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True,\n",
    "    dtype = dtype\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fe1828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- messages[0].content + '\\n\\n' }}\n",
      "    {%- endif %}\n",
      "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
      "{%- for forward_message in messages %}\n",
      "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
      "    {%- set message = messages[index] %}\n",
      "    {%- set current_content = message.content if message.content is defined and message.content is not none else '' %}\n",
      "    {%- set tool_start = '<tool_response>' %}\n",
      "    {%- set tool_start_length = tool_start|length %}\n",
      "    {%- set start_of_message = current_content[:tool_start_length] %}\n",
      "    {%- set tool_end = '</tool_response>' %}\n",
      "    {%- set tool_end_length = tool_end|length %}\n",
      "    {%- set start_pos = (current_content|length) - tool_end_length %}\n",
      "    {%- if start_pos < 0 %}\n",
      "        {%- set start_pos = 0 %}\n",
      "    {%- endif %}\n",
      "    {%- set end_of_message = current_content[start_pos:] %}\n",
      "    {%- if ns.multi_step_tool and message.role == \"user\" and not(start_of_message == tool_start and end_of_message == tool_end) %}\n",
      "        {%- set ns.multi_step_tool = false %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {%- set m_content = message.content if message.content is defined and message.content is not none else '' %}\n",
      "        {%- set content = m_content %}\n",
      "        {%- set reasoning_content = '' %}\n",
      "        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n",
      "            {%- set reasoning_content = message.reasoning_content %}\n",
      "        {%- else %}\n",
      "            {%- if '</think>' in m_content %}\n",
      "                {%- set content = (m_content.split('</think>')|last).lstrip('\\n') %}\n",
      "                {%- set reasoning_content = (m_content.split('</think>')|first).rstrip('\\n') %}\n",
      "                {%- set reasoning_content = (reasoning_content.split('<think>')|last).lstrip('\\n') %}\n",
      "            {%- endif %}\n",
      "        {%- endif %}\n",
      "        {%- if loop.index0 > ns.last_query_index %}\n",
      "            {%- if loop.last or (not loop.last and (not reasoning_content.strip() == '')) %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
      "            {%- else %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "            {%- endif %}\n",
      "        {%- else %}\n",
      "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "        {%- endif %}\n",
      "        {%- if message.tool_calls %}\n",
      "            {%- for tool_call in message.tool_calls %}\n",
      "                {%- if (loop.first and content) or (not loop.first) %}\n",
      "                    {{- '\\n' }}\n",
      "                {%- endif %}\n",
      "                {%- if tool_call.function %}\n",
      "                    {%- set tool_call = tool_call.function %}\n",
      "                {%- endif %}\n",
      "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
      "                {{- tool_call.name }}\n",
      "                {{- '\", \"arguments\": ' }}\n",
      "                {%- if tool_call.arguments is string %}\n",
      "                    {{- tool_call.arguments }}\n",
      "                {%- else %}\n",
      "                    {{- tool_call.arguments | tojson }}\n",
      "                {%- endif %}\n",
      "                {{- '}\\n</tool_call>' }}\n",
      "            {%- endfor %}\n",
      "        {%- endif %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "    {%- if enable_thinking is defined and enable_thinking is false %}\n",
      "        {{- '<think>\\n\\n</think>\\n\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9145c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0061, -0.0928,  0.0251,  ...,  0.0051, -0.0082, -0.0054],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Formatted output:\n",
      " <|im_start|>system\n",
      "Responde usando el contexto<|im_end|>\n",
      "<|im_start|>context\n",
      "Qwen 2.5 tiene 128K de contexto<|im_end|>\n",
      "<|im_start|>user\n",
      "¿Cuánto contexto soporta Qwen?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from transformers import AutoTokenizer\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"./models/Qwen2.5-0.5B\")\n",
    "\n",
    "# 2. Definir manualmente el chat_template con soporte para contextos\n",
    "\n",
    "## Contextual Etiqueta\n",
    "new_tokens = [\"<|im_start|>context\", \"<|context|>\"]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "token_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>context\")\n",
    "print(model.get_input_embeddings().weight[token_id])\n",
    "\n",
    "custom_chat_template = \"\"\"{% for message in messages %}\n",
    "{% if message['role'] == 'system' %}\n",
    "<|im_start|>system\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% elif message['role'] == 'context' %}\n",
    "<|im_start|>context\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% elif message['role'] == 'user' %}\n",
    "<|im_start|>user\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% elif message['role'] == 'assistant' %}\n",
    "<|im_start|>assistant\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "{% if add_generation_prompt %}\n",
    "<|im_start|>assistant\n",
    "{% endif %}\"\"\"\n",
    "\n",
    "# 3. Asignar la plantilla personalizada\n",
    "tokenizer.chat_template = custom_chat_template\n",
    "\n",
    "# 4. Verificar que funciona\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Responde usando el contexto\"},\n",
    "    {\"role\": \"context\", \"content\": \"Qwen 2.5 tiene 128K de contexto\"},\n",
    "    {\"role\": \"user\", \"content\": \"¿Cuánto contexto soporta Qwen?\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(\"Formatted output:\\n\", formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b139024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Escuelas Profesionales de la Facultad de Ciencias de la UNI\\n\\nInformación de Contacto:\\nSegún la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\\n\\nPara Física, Química o Ciencia de la Computación: escuelas_fc1@uni.edu.pe\\nPara Matemáticas o Ingeniería Física: escuelas_fc2@uni.edu.pe\\n\\nHorario de Atención de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\\n\\nÁrea de Estadística y Registros Académicos de la Facultad de Ciencias de la UNI\\n\\nInformación de Contacto de la oficina de estadística (AERA)\\nE-mail: estadistica_fc@uni.edu.pe\\n\\nHorario de Atención de la oficina de estadística (AERA):\\nDe Lunes a Viernes de 8:00 a.m. a 4:00 p.m.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import read_fragment_doc\n",
    "general_contact_information = read_fragment_doc(\"./documentos/informacion_general_contacto.txt\")\n",
    "general_contact_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7a20765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}\n",
      "{% if message['role'] == 'system' %}\n",
      "<|im_start|>system\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'context' %}\n",
      "<|im_start|>context\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'user' %}\n",
      "<|im_start|>user\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% elif message['role'] == 'assistant' %}\n",
      "<|im_start|>assistant\n",
      "{{ message['content'] }}<|im_end|>\n",
      "{% endif %}\n",
      "{% endfor %}\n",
      "{% if add_generation_prompt %}\n",
      "<|im_start|>assistant\n",
      "{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51da1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matrícula, procedimientos y trámites académicos de la Facultad de Ciencias de la Universidad Nacional de Ingeniería del Perú.\n",
      "Deberás responder a los mensajes asegurándote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, útiles y concisas a las preguntas del usuario basándote exclusivamente en el contexto proporcionado.\n",
      "    2. Mantén un tono cordial, empático y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina más idónea, la derivación se realizará hacia la Oficina de Estadística (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empatía que no tienes acceso a dicha información.<|im_end|>\n",
      "<|im_start|>context\n",
      "Fecha De Pago De Autoseguro\n",
      "¿Hasta que fecha se debe realizar el pago por concepto de autoseguro estudiantil para que un estudiante pueda realizar la matrícula regular al ciclo academico en la Facultad de Ciencias de la UNI?\n",
      "Los estudiantes deben realizar el pago del autoseguro estudiantil antes de las fechas de matrícula, dentro del plazo máximo establecido en el calendario de actividades académicas correspondiente al periodo académico. Si no se cumple con este plazo máximo, no se habilitará en el sistema su matricula regular (inscripción de cursos) y deberá gestionar la matricula como rezagada. El estudiante puede verificar esta situación al comprobar si su matrícula se habilita o no en las fechas de matrícula regular. Si la matrícula no se habilita en estas fechas, el estudiante podrá solicitar su matricula rezagada. Sin embargo, la inscripción de cursos de la matricula rezagada se realiza en función de las vacantes disponibles por lo que se corre el riesgo de no alcanzar vacantes para los cursos deseados.\n",
      "El calendario de actividades académicas es publicado en la sección \"MATRÍCULA Y PROCEDIMIENTOS\" de la pagina web de la Facultad de Ciencias, puede acceder a esta sección de la web mediante el siguiente enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Procedimiento De Matricula Rezagada\n",
      "¿Qué procedimiento debe seguir un estudiante de pregrado de la facultad de ciencias de la uni para tramitar su matricula rezagada?\n",
      "La matrícula rezagada se realiza en las fechas establecidas en el calendario de actividades académicas publicado dentro de la sección [\"MATRÍCULA Y PROCEDIMIENTOS\" de la Pagina de la Facultad de Ciencias](https://fc.uni.edu.pe/estadistica/documentos/). Esta matrícula está dirigida a los alumnos ingresantes que no pudieron matricularse en las fechas establecidas en el calendario de actividades académicas, así como a los alumnos regulares que no realizaron su matrícula regular académica en el plazo correspondiente y a los estudiantes reincorporados rezagados.\n",
      "Para poder efectuar la matrícula rezagada, el estudiante no debe tener adeudos pendientes con la facultad ya sea por concepto económico, préstamos de libros u otros materiales de enseñanza en general de la biblioteca y debe haber realizado el pago por concepto de autoseguro médico estudiantil.\n",
      "Cumplidos estos requisitos, deberá seguir los siguientes pasos para completar el proceso::\n",
      "1. Previo a la matrícula rezagada, el estudiante deberá efectuar el pago de S/ 26. Para ello, debe generar la orden de pago por concepto de matricula rezagada a través del portal INTRALU y realizar el pago correspondiente en una agencia del BCP o mediante su banca móvil.\n",
      "2. La matrícula rezagada se realizará exclusivamente a través de la Oficina de Estadística (AERA) de la Facultad, en las fechas establecidas en el calendario de actividades académicas. Para ello, el estudiante deberá presentarse en dichas fechas en la Oficina de Estadística con el comprobante de pago correspondiente.\n",
      "\n",
      "Posterior a la fechas de la matricula rezagada, los estudiantes ya no podrán realizar la matricula en el ciclo académico.\n",
      "\n",
      "Problemas Al Realizar La Matrícula Virtual\n",
      "¿Qué debe hacer un estudiante si presenta problemas para realizar la matricula de sus cursos a traves del modulo de Matrícula UNI dentro de la plataforma de intranet-alumnos?\n",
      "Los estudiantes que encuentren dificultades para completar su proceso de inscripción de cursos a traves del modulo de Matrícula UNI dentro de la plataforma de intranet-alumnos deben verificar si se encuentran en alguna de las siguientes situaciones:\n",
      "    - Poseer algún tipo de adeudo con la Facultad. En caso de ser estudiante en riesgo académico y adeudar la tutoría obligatoria previa a la matricula, deben ponerse en contacto con la Oficina de Tutoría a través del correo electrónico tutoria.fc@uni.edu.pe.\n",
      "\n",
      "    - No haber efectuado el pago del autoseguro en el plazo establecido en el calendario de actividades académicas antes de las fechas de matricula. Si este es el caso y la matrícula virtual (inscripción de cursos) no se ha habilitado hasta los días de matrícula regular, es necesario comunicarse con la oficina de estadística (AERA) o revisar el procedimiento para gestionar su matrícula rezagada.\n",
      "\n",
      "    - Para cualquier otro inconveniente, se recomienda ponerse en contacto directamente con la oficina de estadística (AERA), enviando un mensaje al correo estadistica_fc@uni.edu.pe o acercarse personalmente a dicha oficina.\n",
      "\n",
      "Perdida De Turno De Matricula\n",
      "¿Qué debe hacer un estudiante que no pudo realizar la inscripción de sus cursos de manera virtual en la fecha y turno asignado para su matrícula regular?\n",
      "Si un estudiante no logró inscribirse en sus cursos a tiempo usando el Módulo de Matrícula UNI en la plataforma Intranet-Alumnos, según los plazos establecidos en el calendario académico y en su turno asignado para la matrícula regular del ciclo académico, pero aún quiere inscribirse en el ciclo, deberá gestionar su matrícula rezagada.\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto:\n",
      "Según la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para Física, Química o Ciencia de la Computación: escuelas_fc1@uni.edu.pe\n",
      "Para Matemáticas o Ingeniería Física: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atención de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "Área de Estadística y Registros Académicos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto de la oficina de estadística (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atención de la oficina de estadística (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "Si un alumno no cumplió con el pago del autoseguro, ¿qué procedimiento debe seguir para gestionar su matrícula rezagada?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Si un alumno no cumplió con el pago del autoseguro, no podrá realizar la matrícula rezagada. Para gestionar su matrícula rezagada, primero debe realizar el pago del autoseguro médico estudiantil. Luego, deberá seguir estos pasos:\n",
      "\n",
      "1. Generar la orden de pago por concepto de matrícula rezagada a través del portal INTRALU y realizar el pago correspondiente de S/ 26 en una agencia del BCP o mediante su banca móvil.\n",
      "2. Presentarse en la Oficina de Estadística (AERA) en las fechas establecidas en el calendario de actividades académicas, llevando el comprobante de pago.\n",
      "\n",
      "Recuerde que la matrícula rezagada se realiza solo si se cumplen todos los requisitos y en las fechas establecidas.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from datasets import load_dataset\n",
    "\n",
    "prompt_role_system = \"\"\"Eres Aerito, un asistente de IA especializado en temas de matrícula, procedimientos y trámites académicos de la Facultad de Ciencias de la Universidad Nacional de Ingeniería del Perú.\n",
    "Deberás responder a los mensajes asegurándote de cumplir con los siguientes criterios.\n",
    "    1. Proporcionar respuestas informativas, útiles y concisas a las preguntas del usuario basándote exclusivamente en el contexto proporcionado.\n",
    "    2. Mantén un tono cordial, empático y servicial en sus interacciones.\n",
    "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina más idónea, la derivación se realizará hacia la Oficina de Estadística (AERA) de la Facultad de Ciencias.\n",
    "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empatía que no tienes acceso a dicha información.\"\"\"\n",
    "\n",
    "#tokenizer = get_chat_template(\n",
    "#    tokenizer,\n",
    "#    chat_template = \"qwen-2.5\"\n",
    "#)\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"turns\"]\n",
    "    recovered_texts = examples[\"retrieved_texts\"]\n",
    "    docs_range = examples[\"docs_range\"]\n",
    "\n",
    "    #\"recovered_texts= examples[\"recovered_texts\"],\n",
    "    for convo, texts, doc_range in zip(convos, recovered_texts, docs_range):\n",
    "        if convo[0][\"role\"] != \"system\":\n",
    "            convo.insert(0, {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt_role_system\n",
    "            })\n",
    "            \n",
    "            if texts is not None:\n",
    "                #print(\"texts\", texts)\n",
    "                texts_context = [text[\"text\"] for text in texts[doc_range[0]:doc_range[1]]] + [general_contact_information]\n",
    "                context = \"\\n\\n\".join(texts_context)\n",
    "            \n",
    "                convo.insert(1, {\n",
    "                    \"role\": \"context\",\n",
    "                    \"content\": context\n",
    "                })\n",
    "                #print(\"convo[1]\",convo[1])\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files = {\"train\":\"./conversational_faq/data/train_turns_dataset.json\", \"val\": \"./conversational_faq/data/val_turns_dataset.json\"})\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "print(dataset['train'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60cd19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import is_bf16_supported\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset['train'],\n",
    "    eval_dataset = dataset['val'],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 4,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field= \"text\",\n",
    "        per_device_train_batch_size = 16,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        per_device_eval_batch_size = 8,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=2,\n",
    "        #max_steps=60,\n",
    "        learning_rate= 2e-4,\n",
    "        fp16= not is_bf16_supported(),\n",
    "        bf16= is_bf16_supported(),\n",
    "        logging_steps=1,\n",
    "        eval_strategy= \"epoch\",\n",
    "        save_strategy= \"epoch\",\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        packing = False\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0726108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matrícula, procedimientos y trámites académicos de la Facultad de Ciencias de la Universidad Nacional de Ingeniería del Perú.\n",
      "Deberás responder a los mensajes asegurándote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, útiles y concisas a las preguntas del usuario basándote exclusivamente en el contexto proporcionado.\n",
      "    2. Mantén un tono cordial, empático y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina más idónea, la derivación se realizará hacia la Oficina de Estadística (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empatía que no tienes acceso a dicha información.<|im_end|>\n",
      "<|im_start|>context\n",
      "Generación De Orden De Pago Para Autoseguro\n",
      "¿Cual es el proceso para que un ingresante o alumno regular genere una orden de pago para el pago de autoseguro?\n",
      "Para generar una orden de pago por concepto de autoseguro, el ingresante o alumno regular debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opción \"Trámites\", para acceder al módulo de tramites y pagos. En dicho módulo, selecciona la opción \"PAGO-AUTOSEGURO MEDICO\" en el menú desplegable, haz clic en el botón \"Nuevo\" y sigue las indicaciones hasta generar la orden de pago por el monto de S/. 55.00. Luego de generar la orden de pago el ingresante o estudiante regular podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria. Para mas detalles sobre el proceso para generar un orden de pago puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\n",
      "\n",
      "Procedimiento General Para Generar Una Orden De Pago\n",
      "¿Cuál es el procedimiento que debe seguir un estudiante para generar una orden de pago relacionada con algún concepto o trámite específico y realizar el pago correspondiente?\n",
      "Para generar una orden, el estudiante debe seguir los siguientes pasos:\n",
      "    1. Acceder a la plataforma INTRALU.\n",
      "    2. Dentro de la plataforma, seleccionar la opción \"Trámites\" para acceder al módulo de tramites y pagos.\n",
      "    3. En el módulo de pagos, selecciona el trámite correspondiente en el menú desplegable. Después, haz clic en el botón \"Nuevo\" y siga las indicaciones hasta generar la orden de pago correspondiente.\n",
      "\n",
      "Para cualquier otro trámite que no esté estipulado en la lista de opciones dentro de la plataforma, solicitar la generación de la orden de pago a la oficina de estadística (AERA) al correo estadistica_fc@uni.edu.pe, detallando el concepto del tramite y sus datos personales (DNI, apellidos, nombres, correo institucional) en el mensaje.\n",
      "\n",
      "Una vez generada la orden de pago, el alumno deberá esperar aproximadamente 10 minutos para realizar el pago correspondiente en una sucursal del BCP o a través de la aplicación móvil del banco.\n",
      "\n",
      "Para obtener más detalles sobre el proceso para generar una orden de pago a traves de la plataforma, consulta el Manual de Pagos publicado dentro de la sección de \"MATRÍCULA Y PROCEDIMIENTOS\" en la Página Web de la Facultad de Ciencias, puede ingresar a dicha sección a traves del enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Proceso De Pago De Una Orden De Pago\n",
      "¿Como pagar una orden de pago generada por el algún concepto o tramite?\n",
      "Los ingresantes o estudiantes de la Universidad Nacional de Ingeniería, luego de generar una orden de pago por algún concepto o trámite, pueden realizar el pago en alguna sucursal del BCP o a través de la aplicación móvil del banco. En la app, deben seleccionar \"Pagar servicios\", buscar a la Universidad Nacional de Ingeniería y seleccionarla, luego elegir la opción de pago para estudiantes e ingresar su número de DNI. La aplicación mostrará la orden de pago con el monto exacto para realizar el pago.\n",
      "Se recomienda esperar al menos 10 minutos luego de generar la orden para realizar el pago correspondiente.\n",
      "\n",
      "Reincorporación Después De Una Una Reserva De Matricula\n",
      "¿Qué procedimiento debe seguir un estudiante que desea reincorporarse después de haber reservado su matricula por uno o mas periodos académicos?\n",
      "El estudiante que desee realizar su reincorporación deberá gestionarla antes de las fechas de matrícula dentro del plazo establecido en el calendario de actividades académicas. Para ello, debera realizar los siguientes pasos.\n",
      "    1. Acceder a la Portal INTRALU con su código UNI y clave correspondiente. Luego, seleccionar la opción \"Trámites\" para acceder al módulo de pagos.\n",
      "    2. En el módulo de pagos, seleccionar el trámite correspondiente y genera una nueva orden de pago siguiendo las indicaciones en la plataforma. \n",
      "    3. Una vez generada la orden de pago, el alumno debe realizar el pago en una sucursal del BCP o utilizando la aplicación móvil del BCP. \n",
      "    4. Después de completar el pago, el estudiante debe enviar su solicitud de reincorporación a través de la Plataforma de Intranet-Alumnos dentro de los plazos establecidos (consultar el calendario académico). Para ello accede a la plataforma, elige \"Reincorporación de Estudiantes\" en \"Mis Trámites\", completa el formulario con la solicitud y el comprobante de pago, y envía la solicitud.\n",
      "\n",
      "Al completar el envió de la solicitud por la plataforma se visualizara la solicitud enviada, la fecha de envio y estado actual de la solicitud.\n",
      "Una vez aprobada y realizada la reincorporación, el estudiante podrá realizar su matrícula de manera regular.\n",
      "\n",
      "Matricula Ingresantes\n",
      "Los nuevos ingresantes a la Facultad de Ciencias de la Universidad Nacional de Ingenieria, deberan seguir realizar el siguiente proceso para completar su matricula (primera matricula al primer ciclo):\n",
      "    1. Recabar su constancia de ingreso. Luego de gestionar la emisión de su constancia de ingreso, la Dirección de Admisión (DIAD) de la UNI enviará a su correo electrónico la constancia de ingreso. Para más detalles sobre el proceso, puede consultar con DIAD al correo informes.admision@uni.edu.pe. \n",
      "    2. Actualizacion de datos en DIRCE. La Dirección de Registros Central y Estadística hará llegar a su correo su clave para acceder a la plataforma para intranet-alumnos y completar sus datos.\n",
      "    3. Registrar los datos en la Facultad de Ciencias. La oficina de estadística enviará al correo del ingresante la ficha de datos. El llenado es carácter obligatorio.\n",
      "    4. Efectuar el pago por autoseguro dentro del plazo establecido en el cronograma de actividades academicas publicado en la pagina web de la Facultad de ciencias. Para ello, el ingresante debera generar una orden de pago atravez del portal INTRALU, luego podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria.\n",
      "    5. Realizar la entrega de los siguientes documentos a la oficina de estadística según el cronograma de actividades de matrícula de ingresantes publicado en la sección 'MATRÍCULA Y PROCEDIMIENTOS' en la página web de la Facultad de Ciencias.\n",
      "        - Contancia de Ingreso\n",
      "        - Ficha de datos Personales. Enviada por la oficina de estadística al correo del ingresante.\n",
      "        - Constancia de Evaluacion Socioeconomica. El ingresante debera acudir a la cita para su evaluacion socioeconomica que le llegara a su correo. \n",
      "        - Certificado Médico expedido por el Centro Medico UNI. Para ello acudir a su examen medico segun los cronograma publicados por la Dirección de Admisión. \n",
      "        - Comprobante de pago de Autoseguro Estudiantil\n",
      "    6. AERA ejecutará la matrícula (inscripción de cursos) de los ingresantes según el cronograma de actividades, únicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\n",
      "    7. Los ingresantes matriculados recibirán un mensaje en su correo con el horario de sus cursos, ademas podran visualizar los cursos y horarios dentro del portal INTRALU.\n",
      "\n",
      "Para generar una orden de pago, el ingresante debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opción \"Trámites\" para acceder al módulo de pagos. En dicho módulo, selecciona el trámite correspondiente en el menú desplegable, haz clic en el botón \"Nuevo\" y sigue las indicaciones hasta generar la orden de pago. Para mas detalles sobre el proceso para generar un orden de pogo puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\n",
      "\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto:\n",
      "Según la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para Física, Química o Ciencia de la Computación: escuelas_fc1@uni.edu.pe\n",
      "Para Matemáticas o Ingeniería Física: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atención de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "Área de Estadística y Registros Académicos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto de la oficina de estadística (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atención de la oficina de estadística (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "Si un alumno no cumplió con el pago del autoseguro, ¿qué procedimiento debe seguir para gestionar su matrícula rezagada?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Si un alumno no cumplió con el pago del autoseguro, no podrá realizar la matrícula rezagada. Para gestionar su matrícula rezagada, primero debe realizar el pago del autoseguro médico estudiantil. Luego, deberá seguir estos pasos:\n",
      "\n",
      "1. Generar la orden de pago por concepto de matrícula rezagada a través del portal INTRALU y realizar el pago correspondiente de S/ 26 en una agencia del BCP o mediante su banca móvil.\n",
      "2. Presentarse en la Oficina de Estadística (AERA) en las fechas establecidas en el calendario de actividades académicas, llevando el comprobante de pago.\n",
      "\n",
      "Recuerde que la matrícula rezagada se realiza solo si se cumplen todos los requisitos y en las fechas establecidas.<|im_end|>\n",
      "<|im_start|>user\n",
      "¿Y si ya pagué el autoseguro, pero tengo dudas sobre cómo generar la orden de pago en INTRALU? ¿Hay algún tutorial o guía que me recomiendes?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Para generar la orden de pago en INTRALU, debes acceder a la plataforma y seguir estos pasos:\n",
      "\n",
      "1. Selecciona la opción \"Trámites\" para acceder al módulo de trámites y pagos.\n",
      "2. En el módulo, elige \"PAGO-AUTOSEGURO MEDICO\" en el menú desplegable.\n",
      "3. Haz clic en el botón \"Nuevo\" y sigue las indicaciones hasta generar la orden de pago por S/. 55.00.\n",
      "\n",
      "Para más detalles sobre el proceso, puedes consultar el Manual de Pagos publicado en la sección \"MATRÍCULA Y PROCEDIMIENTOS\" en la página web de la Facultad de Ciencias. Si tienes más dudas, no dudes en preguntar.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(trainer.train_dataset[1][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cf3a951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA RTX 4500 Ada Generation. Max memory = 23.994 GB.\n",
      "10.432 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed1bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 5,821 | Num Epochs = 2 | Total steps = 182\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 4 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 40,370,176/600,000,000 (6.73% trained)\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "734084f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected local model directory: ./models/unsloth-Qwen3-0.6B\n",
      "Found HuggingFace hub cache directory: /home/anthony/.cache/huggingface/hub\n",
      "Copying safetensors from local directory: ./models/unsloth-Qwen3-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"models/qwen3-finetuned-merged\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5f51e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA RTX 4500 Ada Generation. Num GPUs = 1. Max memory: 23.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Embedding:\n\tsize mismatch for weight: copying a param with shape torch.Size([151936, 1024]) from checkpoint, the shape in current model is torch.Size([151671, 1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, tokenizer = \u001b[43mFastLanguageModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./models/qwen3-finetuned-merged\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/loader.py:376\u001b[39m, in \u001b[36mFastLanguageModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, *args, **kwargs)\u001b[39m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m model, tokenizer = \u001b[43mdispatch_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/qwen3.py:419\u001b[39m, in \u001b[36mFastQwen3Model.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(  \u001b[38;5;66;03m#TODO: Change after release\u001b[39;00m\n\u001b[32m    406\u001b[39m     model_name        = \u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen3-7B\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    417\u001b[39m     **kwargs,\n\u001b[32m    418\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastLlamaModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mFastQwen3Model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1840\u001b[39m, in \u001b[36mFastLlamaModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, **kwargs)\u001b[39m\n\u001b[32m   1837\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit: kwargs[\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m] = bnb_config\n\u001b[32m   1839\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fast_inference:\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m     model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m              \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# quantization_config     = bnb_config,\u001b[39;49;00m\n\u001b[32m   1845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meager\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1849\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1850\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1851\u001b[39m     model.fast_generate = model.generate\n\u001b[32m   1852\u001b[39m     model.fast_generate_batches = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:4574\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4564\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4565\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4567\u001b[39m     (\n\u001b[32m   4568\u001b[39m         model,\n\u001b[32m   4569\u001b[39m         missing_keys,\n\u001b[32m   4570\u001b[39m         unexpected_keys,\n\u001b[32m   4571\u001b[39m         mismatched_keys,\n\u001b[32m   4572\u001b[39m         offload_index,\n\u001b[32m   4573\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4574\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4580\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4583\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4590\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4592\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4593\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:5031\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5029\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m   5030\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m-> \u001b[39m\u001b[32m5031\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5042\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5043\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5045\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5047\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[32m   5050\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:843\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled():\n\u001b[32m    841\u001b[39m         param_device = \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[43m_load_parameter_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    846\u001b[39m     hf_quantizer.create_quantized_param(\n\u001b[32m    847\u001b[39m         model, param, param_name, param_device, state_dict, unexpected_keys\n\u001b[32m    848\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:731\u001b[39m, in \u001b[36m_load_parameter_into_model\u001b[39m\u001b[34m(model, param_name, tensor)\u001b[39m\n\u001b[32m    729\u001b[39m module, param_type = get_module_from_name(model, param_name)\n\u001b[32m    730\u001b[39m \u001b[38;5;66;03m# This will check potential shape mismatch if skipped before\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mparam_type\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Embedding:\n\tsize mismatch for weight: copying a param with shape torch.Size([151936, 1024]) from checkpoint, the shape in current model is torch.Size([151671, 1024])."
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name =  \"./models/qwen3-finetuned-merged\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86788235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"models/qwen3-finetuned-merged\", torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"models/qwen3-finetuned-merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddd998e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151669\n",
      "151670\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.get_vocab().get(\"<|im_start|>context\"))  # Debería imprimir un ID, no None\n",
    "print(tokenizer.get_vocab().get(\"<|context|>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dec6478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/qwen3-finetuned/tokenizer_config.json',\n",
       " 'models/qwen3-finetuned/special_tokens_map.json',\n",
       " 'models/qwen3-finetuned/chat_template.jinja',\n",
       " 'models/qwen3-finetuned/vocab.json',\n",
       " 'models/qwen3-finetuned/merges.txt',\n",
       " 'models/qwen3-finetuned/added_tokens.json',\n",
       " 'models/qwen3-finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"models/qwen3-finetuned\")\n",
    "tokenizer.save_pretrained(\"models/qwen3-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12540a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected local model directory: ./models/unsloth-Qwen3-0.6B\n",
      "Found HuggingFace hub cache directory: /home/inictel-ivan/.cache/huggingface/hub\n",
      "Copying safetensors from local directory: ./models/unsloth-Qwen3-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected local model directory: ./models/unsloth-Qwen3-0.6B\n",
      "Unsloth: Merging LoRA weights into 4bit model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inictel-ivan/miniconda3/envs/llm/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging finished.\n",
      "Unsloth: Found skipped modules: ['lm_head']. Updating config.\n",
      "Unsloth: Saving merged 4bit model to models/qwen3-finetuned-4bit...\n",
      "Unsloth: Merged 4bit model saved.\n",
      "Unsloth: Merged 4bit model process completed.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"models/qwen3-finetuned-16bit\", tokenizer, save_method = \"merged_16bit\",)\n",
    "model.save_pretrained_merged(\"models/qwen3-finetuned-4bit\", tokenizer, save_method = \"merged_4bit_forced\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4cd8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected local model directory: ./models/unsloth-Qwen3-0.6B\n",
      "Found HuggingFace hub cache directory: /home/anthony/.cache/huggingface/hub\n",
      "Copying safetensors from local directory: ./models/unsloth-Qwen3-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|██████████| 1/1 [00:05<00:00,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"models/qwen3-finetuned-merged\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03564325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_merged(\"models/qwen3-finetuned-merged\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa32cd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA RTX 4500 Ada Generation. Num GPUs = 1. Max memory: 23.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Embedding:\n\tsize mismatch for weight: copying a param with shape torch.Size([151936, 1024]) from checkpoint, the shape in current model is torch.Size([151671, 1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, tokenizer = \u001b[43mFastLanguageModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./models/qwen3-finetuned-merged\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#fast_inference = True,\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#max_lora_rank = lora_rank,\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#gpu_memory_utilization = 0.5\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/loader.py:376\u001b[39m, in \u001b[36mFastLanguageModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, *args, **kwargs)\u001b[39m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m model, tokenizer = \u001b[43mdispatch_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/qwen3.py:419\u001b[39m, in \u001b[36mFastQwen3Model.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(  \u001b[38;5;66;03m#TODO: Change after release\u001b[39;00m\n\u001b[32m    406\u001b[39m     model_name        = \u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen3-7B\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    417\u001b[39m     **kwargs,\n\u001b[32m    418\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastLlamaModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mFastQwen3Model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1840\u001b[39m, in \u001b[36mFastLlamaModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, **kwargs)\u001b[39m\n\u001b[32m   1837\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit: kwargs[\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m] = bnb_config\n\u001b[32m   1839\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fast_inference:\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m     model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m              \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# quantization_config     = bnb_config,\u001b[39;49;00m\n\u001b[32m   1845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meager\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1849\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1850\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1851\u001b[39m     model.fast_generate = model.generate\n\u001b[32m   1852\u001b[39m     model.fast_generate_batches = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:4574\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4564\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4565\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4567\u001b[39m     (\n\u001b[32m   4568\u001b[39m         model,\n\u001b[32m   4569\u001b[39m         missing_keys,\n\u001b[32m   4570\u001b[39m         unexpected_keys,\n\u001b[32m   4571\u001b[39m         mismatched_keys,\n\u001b[32m   4572\u001b[39m         offload_index,\n\u001b[32m   4573\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4574\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4580\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4583\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4590\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4592\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4593\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:5031\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5029\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m   5030\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m-> \u001b[39m\u001b[32m5031\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5042\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5043\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5045\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5047\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[32m   5050\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:843\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled():\n\u001b[32m    841\u001b[39m         param_device = \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[43m_load_parameter_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    846\u001b[39m     hf_quantizer.create_quantized_param(\n\u001b[32m    847\u001b[39m         model, param, param_name, param_device, state_dict, unexpected_keys\n\u001b[32m    848\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_utils.py:731\u001b[39m, in \u001b[36m_load_parameter_into_model\u001b[39m\u001b[34m(model, param_name, tensor)\u001b[39m\n\u001b[32m    729\u001b[39m module, param_type = get_module_from_name(model, param_name)\n\u001b[32m    730\u001b[39m \u001b[38;5;66;03m# This will check potential shape mismatch if skipped before\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mparam_type\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Embedding:\n\tsize mismatch for weight: copying a param with shape torch.Size([151936, 1024]) from checkpoint, the shape in current model is torch.Size([151671, 1024])."
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name =  \"./models/qwen3-finetuned-merged\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True,\n",
    "    #fast_inference = True,\n",
    "    #max_lora_rank = lora_rank,\n",
    "    #gpu_memory_utilization = 0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389d059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/qwen3-finetuned/tokenizer_config.json',\n",
       " 'models/qwen3-finetuned/special_tokens_map.json',\n",
       " 'models/qwen3-finetuned/chat_template.jinja',\n",
       " 'models/qwen3-finetuned/vocab.json',\n",
       " 'models/qwen3-finetuned/merges.txt',\n",
       " 'models/qwen3-finetuned/added_tokens.json',\n",
       " 'models/qwen3-finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el modelo fine-tuneado\n",
    "\n",
    "# Fusionar adaptadores LoRA (si se usaron) con el modelo base\n",
    "#model = model.merge_and_unload()\n",
    "\n",
    "# Guardar el modelo completo ya fusionado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matrícula, procedimientos y trámites académicos de la Facultad de Ciencias de la Universidad Nacional de Ingeniería del Perú.\n",
      "Deberás responder a los mensajes asegurándote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, útiles y concisas a las preguntas del usuario basándote exclusivamente en el contexto proporcionado.\n",
      "    2. Mantén un tono cordial, empático y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina más idónea, la derivación se realizará hacia la Oficina de Estadística (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empatía que no tienes acceso a dicha información.<|im_end|>\n",
      "<|im_start|>context\n",
      "Fecha De Pago De Autoseguro\n",
      "¿Hasta que fecha se debe realizar el pago por concepto de autoseguro estudiantil para que un estudiante pueda realizar la matrícula regular al ciclo academico en la Facultad de Ciencias de la UNI?\n",
      "Los estudiantes deben realizar el pago del autoseguro estudiantil antes de las fechas de matrícula, dentro del plazo máximo establecido en el calendario de actividades académicas correspondiente al periodo académico. Si no se cumple con este plazo máximo, no se habilitará en el sistema su matricula regular (inscripción de cursos) y deberá gestionar la matricula como rezagada. El estudiante puede verificar esta situación al comprobar si su matrícula se habilita o no en las fechas de matrícula regular. Si la matrícula no se habilita en estas fechas, el estudiante podrá solicitar su matricula rezagada. Sin embargo, la inscripción de cursos de la matricula rezagada se realiza en función de las vacantes disponibles por lo que se corre el riesgo de no alcanzar vacantes para los cursos deseados.\n",
      "El calendario de actividades académicas es publicado en la sección \"MATRÍCULA Y PROCEDIMIENTOS\" de la pagina web de la Facultad de Ciencias, puede acceder a esta sección de la web mediante el siguiente enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto:\n",
      "Según la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para Física, Química o Ciencia de la Computación: escuelas_fc1@uni.edu.pe\n",
      "Para Matemáticas o Ingeniería Física: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atención de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "Área de Estadística y Registros Académicos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto de la oficina de estadística (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atención de la oficina de estadística (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "¿Qué métodos de pago pueden usar los estudiantes para su orden de pago de autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Los estudiantes pueden realizar el pago de la orden de pago por concepto de autoseguro a través de dos métodos: en alguna sucursal del BCP o mediante la aplicación móvil del banco BCP. Se recomienda esperar al menos 10 minutos después de generar la orden de pago antes de proceder con el pago. Si necesitas más información, no dudes en preguntar.<|im_end|>\n",
      "<|im_start|>user\n",
      "¿Y qué pasa si no tengo cuenta en el BCP? ¿Hay otras opciones para pagar el autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Lamentablemente, solo se menciona el pago del autoseguro a través de sucursales del BCP o mediante la aplicación móvil del mismo banco. No tengo acceso a información sobre otras opciones de pago disponibles. Te sugiero que contactes a la Oficina de Estadística de la Facultad de Ciencias para obtener más detalles sobre posibles alternativas. Su correo es estadistica_fc@uni.edu.pe y su horario de atención es de lunes a viernes de 8:00 a.m. a 4:00 p.m. Si necesitas más ayuda, no dudes en preguntar.<|im_end|>\n",
      "<|im_start|>user\n",
      "Entendido. Voy a contactar a la Oficina de Estadística para ver si tienen más opciones. ¿Sabes si hay algún plazo específico para hacer el pago del autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El autoseguro se ha comenzado a ofrecer, por lo que no se menciona un plazo específico para realizar el pago. Sin embargo, es importante que los estudiantes cumplan con este proceso antes de las fechas de matrícula, dentro del plazo máximo establecido en el calendario de actividades académicas correspondiente al periodo académico. Si necesitas más información, no dudes en preguntar.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from transformers import TextStreamer\n",
    "\n",
    "dtype = None\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "\n",
    "messages = dataset['train'][5]['turns'][:-1]\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs , \n",
    "    max_new_tokens = 256, \n",
    "    use_cache = True, \n",
    "    streamer = streamer,\n",
    "    temperature = 1.5, \n",
    "    min_p = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b052bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Eres Aerito, un asistente de IA especializado en temas de matrícula, procedimientos y trámites académicos de la Facultad de Ciencias de la Universidad Nacional de Ingeniería del Perú.\n",
      "Deberás responder a los mensajes asegurándote de cumplir con los siguientes criterios.\n",
      "    1. Proporcionar respuestas informativas, útiles y concisas a las preguntas del usuario basándote exclusivamente en el contexto proporcionado.\n",
      "    2. Mantén un tono cordial, empático y servicial en sus interacciones.\n",
      "    3. Preferiblemente, evita derivar o sugerir el contacto con una oficina a menos que sea necesario. Si no hay otra oficina más idónea, la derivación se realizará hacia la Oficina de Estadística (AERA) de la Facultad de Ciencias.\n",
      "    4. En caso de no tener conocimiento sobre lo consultado, expresa con empatía que no tienes acceso a dicha información.<|im_end|>\n",
      "<|im_start|>context\n",
      "Fecha De Pago De Autoseguro\n",
      "¿Hasta que fecha se debe realizar el pago por concepto de autoseguro estudiantil para que un estudiante pueda realizar la matrícula regular al ciclo academico en la Facultad de Ciencias de la UNI?\n",
      "Los estudiantes deben realizar el pago del autoseguro estudiantil antes de las fechas de matrícula, dentro del plazo máximo establecido en el calendario de actividades académicas correspondiente al periodo académico. Si no se cumple con este plazo máximo, no se habilitará en el sistema su matricula regular (inscripción de cursos) y deberá gestionar la matricula como rezagada. El estudiante puede verificar esta situación al comprobar si su matrícula se habilita o no en las fechas de matrícula regular. Si la matrícula no se habilita en estas fechas, el estudiante podrá solicitar su matricula rezagada. Sin embargo, la inscripción de cursos de la matricula rezagada se realiza en función de las vacantes disponibles por lo que se corre el riesgo de no alcanzar vacantes para los cursos deseados.\n",
      "El calendario de actividades académicas es publicado en la sección \"MATRÍCULA Y PROCEDIMIENTOS\" de la pagina web de la Facultad de Ciencias, puede acceder a esta sección de la web mediante el siguiente enlace: https://fc.uni.edu.pe/estadistica/documentos/\n",
      "\n",
      "Escuelas Profesionales de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto:\n",
      "Según la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\n",
      "\n",
      "Para Física, Química o Ciencia de la Computación: escuelas_fc1@uni.edu.pe\n",
      "Para Matemáticas o Ingeniería Física: escuelas_fc2@uni.edu.pe\n",
      "\n",
      "Horario de Atención de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\n",
      "\n",
      "Área de Estadística y Registros Académicos de la Facultad de Ciencias de la UNI\n",
      "\n",
      "Información de Contacto de la oficina de estadística (AERA)\n",
      "E-mail: estadistica_fc@uni.edu.pe\n",
      "\n",
      "Horario de Atención de la oficina de estadística (AERA):\n",
      "De Lunes a Viernes de 8:00 a.m. a 4:00 p.m.<|im_end|>\n",
      "<|im_start|>user\n",
      "¿Qué métodos de pago pueden usar los estudiantes para su orden de pago de autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Los estudiantes pueden realizar el pago de la orden de pago por concepto de autoseguro a través de dos métodos: en alguna sucursal del BCP o mediante la aplicación móvil del banco BCP. Se recomienda esperar al menos 10 minutos después de generar la orden de pago antes de proceder con el pago. Si necesitas más información, no dudes en preguntar.<|im_end|>\n",
      "<|im_start|>user\n",
      "¿Y qué pasa si no tengo cuenta en el BCP? ¿Hay otras opciones para pagar el autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Lamentablemente, solo se menciona el pago del autoseguro a través de sucursales del BCP o mediante la aplicación móvil del mismo banco. No tengo acceso a información sobre otras opciones de pago disponibles. Te sugiero que contactes a la Oficina de Estadística de la Facultad de Ciencias para obtener más detalles sobre posibles alternativas. Su correo es estadistica_fc@uni.edu.pe y su horario de atención es de lunes a viernes de 8:00 a.m. a 4:00 p.m. Si necesitas más ayuda, no dudes en preguntar.<|im_end|>\n",
      "<|im_start|>user\n",
      "Entendido. Voy a contactar a la Oficina de Estadística para ver si tienen más opciones. ¿Sabes si hay algún plazo específico para hacer el pago del autoseguro?<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked about specific payment deadlines for university students regarding student health insurance. I need to check if there's a specific date when they must pay this insurance for the semester.\n",
      "\n",
      "First, I should look up the information from the provided context. In the given information, it mentions that students must pay the insurance before the enrollment dates, and if they don't, they can reschedule. The dates for payment and rescheduling are mentioned as the maximum allowed period, so there is no "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     15\u001b[39m streamer = TextStreamer(tokenizer)\n\u001b[32m     17\u001b[39m inputs = tokenizer.apply_chat_template(\n\u001b[32m     18\u001b[39m     messages,\n\u001b[32m     19\u001b[39m     tokenize = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     20\u001b[39m     add_generation_prompt = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     21\u001b[39m     return_tensors = \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m ).to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m#print(tokenizer.batch_decode(outputs)[0])\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1634\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1632\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1638\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1639\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1640\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:3560\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3560\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3562\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3563\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3564\u001b[39m     outputs,\n\u001b[32m   3565\u001b[39m     model_kwargs,\n\u001b[32m   3566\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1086\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_CausalLM_fast_forward\u001b[39m(\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1070\u001b[39m     input_ids: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1083\u001b[39m     *args, **kwargs,\n\u001b[32m   1084\u001b[39m ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[32m   1085\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1086\u001b[39m         outputs = \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1094\u001b[39m         causal_mask = xformers.attn_bias.LowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1019\u001b[39m, in \u001b[36m_LlamaModel_fast_forward_inference.<locals>.LlamaModel_fast_forward_inference_custom\u001b[39m\u001b[34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[39m\n\u001b[32m   1011\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[32m   1012\u001b[39m X = fast_rms_layernorm_inference(\n\u001b[32m   1013\u001b[39m     decoder_layer.input_layernorm,\n\u001b[32m   1014\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1017\u001b[39m     variance = variance,\n\u001b[32m   1018\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m X, present_key_value = \u001b[43mattention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpaged_attention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m X += residual\n\u001b[32m   1029\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/qwen3.py:283\u001b[39m, in \u001b[36mQwen3Attention_fast_forward_inference\u001b[39m\u001b[34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[39m\n\u001b[32m    281\u001b[39m Qn = fast_linear_forward(\u001b[38;5;28mself\u001b[39m.q_proj, Xn, out = \u001b[38;5;28mself\u001b[39m.temp_QA[\u001b[32m0\u001b[39m])\n\u001b[32m    282\u001b[39m Kn = fast_linear_forward(\u001b[38;5;28mself\u001b[39m.k_proj, Xn, out = \u001b[38;5;28mself\u001b[39m.temp_KV[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m Vn = \u001b[43mfast_linear_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv_proj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemp_KV\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m Qn = Qn.view(bsz, \u001b[32m1\u001b[39m, n_heads,    head_dim)\u001b[38;5;66;03m#.transpose(1, 2) # we will transpose after normalisation\u001b[39;00m\n\u001b[32m    285\u001b[39m Kn = Kn.view(bsz, \u001b[32m1\u001b[39m, n_kv_heads, head_dim)\u001b[38;5;66;03m#.transpose(1, 2) # we will transpose after normalisation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/kernels/utils.py:440\u001b[39m, in \u001b[36mfast_linear_forward\u001b[39m\u001b[34m(proj, X, temp_lora, out)\u001b[39m\n\u001b[32m    438\u001b[39m     out = torch_matmul(X, W.t(), out = out)\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m bsz == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_len == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     out = \u001b[43mfast_gemv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    442\u001b[39m     W = fast_dequantize(W.t(), W_quant, use_global_buffer = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/kernels/utils.py:346\u001b[39m, in \u001b[36mfast_gemv\u001b[39m\u001b[34m(X, W, quant_state, out)\u001b[39m\n\u001b[32m    344\u001b[39m df = torch_empty(absmax.shape, dtype = torch.float32, device = device)\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch_cuda_device(device):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[43mcdequantize_blockwise_fp32\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsmax2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes_c_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocksize2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes_c_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCUDA_STREAM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     df += offset\n\u001b[32m    351\u001b[39m     absmax = df\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "from transformers import TextStreamer\n",
    "\n",
    "#tokenizer = get_chat_template(\n",
    "#    tokenizer,\n",
    "#    chat_template = \"qwen-2.5\",\n",
    "#)\n",
    "\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "\n",
    "messages = dataset['train'][5]['turns'][:-1]\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs , \n",
    "    max_new_tokens = 256, \n",
    "    use_cache = True, \n",
    "    streamer = streamer,\n",
    "    temperature = 1.5, \n",
    "    min_p = 0.1)\n",
    "\n",
    "\n",
    "#print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4845767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparate Conversations:   0%|          | 0/1919 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparate Conversations: 100%|██████████| 1919/1919 [00:00<00:00, 3310.07it/s]\n",
      "Batching:   0%|          | 0/160 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "!handles_.at(i) INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":396, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     38\u001b[39m tokenized = tokenizer(\n\u001b[32m     39\u001b[39m     batch_inputs,\n\u001b[32m     40\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m     padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     42\u001b[39m     truncation=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     43\u001b[39m ).to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Decodificar solo lo nuevo generado por cada ejemplo\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1634\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1632\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1638\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1639\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1640\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:3557\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3554\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3557\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1103\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28mself\u001b[39m.model._has_no_labels = labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1116\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:924\u001b[39m, in \u001b[36mLlamaModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    921\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:592\u001b[39m, in \u001b[36mLlamaDecoderLayer_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m residual = hidden_states\n\u001b[32m    591\u001b[39m hidden_states = fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m.input_layernorm, hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    605\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/qwen3.py:187\u001b[39m, in \u001b[36mQwen3Attention_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m Q, K, V = Q.contiguous(), K.contiguous(), V.contiguous()\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# Needs (batch_size, n_heads, seq_len, head_dim)\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# is_casual and attention_mask must not be both set!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m A = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Go back to (batch_size, seq_len, n_heads, head_dim)\u001b[39;00m\n\u001b[32m    189\u001b[39m A = A.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n",
      "\u001b[31mRuntimeError\u001b[39m: !handles_.at(i) INTERNAL ASSERT FAILED at \"/pytorch/c10/cuda/CUDACachingAllocator.cpp\":396, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "generation_outputs = dict(messages = [], pred_outputs = [], true_outputs = [])\n",
    "\n",
    "val_dataset = dataset['val']\n",
    "\n",
    "# Preparamos las entradas (messages + labels separados)\n",
    "inputs_list = []\n",
    "true_outputs = []\n",
    "messages_list = []\n",
    "\n",
    "tokenizer.padding_side = \"left\"  # importante para generación\n",
    "\n",
    "for conv in tqdm(val_dataset,desc = \"Preparate Conversations\"):\n",
    "    messages = conv['turns'][:-1]\n",
    "    messages_list.append(messages)\n",
    "    input = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    inputs_list.append(input)\n",
    "    true_outputs.append(conv['turns'][-1][\"content\"])\n",
    "\n",
    "# Procesamos por batch\n",
    "batch_size = 12\n",
    "\n",
    "for i in tqdm(range(0, len(inputs_list), batch_size), desc=\"Batching\"):\n",
    "    batch_inputs = inputs_list[i:i+batch_size]\n",
    "    batch_truths = true_outputs[i:i+batch_size]\n",
    "    batch_messages = messages_list[i:i+batch_size]\n",
    "\n",
    "    # Tokenizar y padear batch\n",
    "    tokenized = tokenizer(\n",
    "        batch_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=tokenized[\"input_ids\"],\n",
    "            attention_mask=tokenized[\"attention_mask\"],\n",
    "            max_new_tokens=256,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    # Decodificar solo lo nuevo generado por cada ejemplo\n",
    "    for j in range(len(outputs)):\n",
    "        input_len = tokenized[\"input_ids\"][j].shape[0]\n",
    "        generated_tokens = outputs[j][input_len:]\n",
    "        generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "        generation_outputs[\"messages\"].append(batch_messages[j])\n",
    "        generation_outputs[\"pred_outputs\"].append(generated_text)\n",
    "        generation_outputs[\"true_outputs\"].append(batch_truths[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14591eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>pred_outputs</th>\n",
       "      <th>true_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>El Manual de Pagos está disponible en la secci...</td>\n",
       "      <td>El Manual de Pagos está disponible en la secci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>No hay un plazo específico mencionado para gen...</td>\n",
       "      <td>No hay un plazo específico mencionado para gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>Sí, puedes consultar el estado de tu matrícula...</td>\n",
       "      <td>Sí, puedes consultar el estado de tu matrícula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>Algunos estudiantes pueden enfrentar problemas...</td>\n",
       "      <td>Los problemas comunes que los estudiantes suel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>Sí, puedes contactar a la Oficina de Estadísti...</td>\n",
       "      <td>La Oficina de Estadística (AERA) de la Faculta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>¡De nada! Me alegra haber podido ayudarte. Si ...</td>\n",
       "      <td>¡De nada! Me alegra haber podido ayudarte. Si ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>Para fijar el límite de créditos para estudian...</td>\n",
       "      <td>El límite de créditos para estudiantes que han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>La Tabla 1 del Reglamento de Matrícula está di...</td>\n",
       "      <td>La Tabla 1 del Reglamento de Matrícula está di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "1  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "2  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "3  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "4  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "5  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "6  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "7  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "\n",
       "                                        pred_outputs  \\\n",
       "0  El Manual de Pagos está disponible en la secci...   \n",
       "1  No hay un plazo específico mencionado para gen...   \n",
       "2  Sí, puedes consultar el estado de tu matrícula...   \n",
       "3  Algunos estudiantes pueden enfrentar problemas...   \n",
       "4  Sí, puedes contactar a la Oficina de Estadísti...   \n",
       "5  ¡De nada! Me alegra haber podido ayudarte. Si ...   \n",
       "6  Para fijar el límite de créditos para estudian...   \n",
       "7  La Tabla 1 del Reglamento de Matrícula está di...   \n",
       "\n",
       "                                        true_outputs  \n",
       "0  El Manual de Pagos está disponible en la secci...  \n",
       "1  No hay un plazo específico mencionado para gen...  \n",
       "2  Sí, puedes consultar el estado de tu matrícula...  \n",
       "3  Los problemas comunes que los estudiantes suel...  \n",
       "4  La Oficina de Estadística (AERA) de la Faculta...  \n",
       "5  ¡De nada! Me alegra haber podido ayudarte. Si ...  \n",
       "6  El límite de créditos para estudiantes que han...  \n",
       "7  La Tabla 1 del Reglamento de Matrícula está di...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(generation_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:   0%|          | 0/1919 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k', 'cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Conversations:   0%|          | 0/1919 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     15\u001b[39m generation_outputs[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m].append(messages)\n\u001b[32m     17\u001b[39m inputs = tokenizer.apply_chat_template(\n\u001b[32m     18\u001b[39m     messages,\n\u001b[32m     19\u001b[39m     tokenize = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     20\u001b[39m     add_generation_prompt = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     21\u001b[39m     return_tensors = \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m text_output = tokenizer.decode(outputs[\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(inputs[\u001b[32m0\u001b[39m]):], skip_special_tokens = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     32\u001b[39m generation_outputs[\u001b[33m'\u001b[39m\u001b[33mpred_outputs\u001b[39m\u001b[33m'\u001b[39m].append(text_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1634\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1632\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1638\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1639\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1640\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:3557\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3554\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3557\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:1103\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28mself\u001b[39m.model._has_no_labels = labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1116\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/unsloth/models/llama.py:708\u001b[39m, in \u001b[36mLlamaModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;66;03m# Embed positions\u001b[39;00m\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m inputs_embeds = inputs_embeds.to(_get_dtype(\u001b[38;5;28mself\u001b[39m.config.torch_dtype))\n\u001b[32m    712\u001b[39m \u001b[38;5;66;03m# Normalized from Gemma\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "generation_outputs = dict(messages = [], pred_outputs = [], true_outputs = [])\n",
    "\n",
    "val_dataset = dataset['val']\n",
    "\n",
    "for conv in tqdm(val_dataset, desc= \"Conversations\"):\n",
    "    messages = conv['turns'][:-1]\n",
    "    \n",
    "    generation_outputs['messages'].append(messages)\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = True,\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids = inputs , \n",
    "        max_new_tokens = 256, \n",
    "        use_cache = False, \n",
    "        temperature = 0.0,\n",
    "        do_sample = False)\n",
    "    \n",
    "    text_output = tokenizer.decode(outputs[0, len(inputs[0]):], skip_special_tokens = True)\n",
    "    generation_outputs['pred_outputs'].append(text_output)\n",
    "    generation_outputs['true_outputs'].append(conv['turns'][-1][\"content\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6312891b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>pred_outputs</th>\n",
       "      <th>true_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'Eres Aerito, un asistente de IA ...</td>\n",
       "      <td>El Manual de Pagos está disponible en la secci...</td>\n",
       "      <td>El Manual de Pagos está disponible en la secci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [{'content': 'Eres Aerito, un asistente de IA ...   \n",
       "\n",
       "                                        pred_outputs  \\\n",
       "0  El Manual de Pagos está disponible en la secci...   \n",
       "\n",
       "                                        true_outputs  \n",
       "0  El Manual de Pagos está disponible en la secci...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(generation_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5613b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from utils import save_json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "convs_sim_file = \"./conversational_faq/openline-questions/conv_sim_derived_questions_faq_33_0_to_7.json\"\n",
    "\n",
    "files = glob(\"./conversational_faq/openline-questions/*.json\")\n",
    "\n",
    "for file_path in tqdm(files, desc= \"File\"): \n",
    "    with open(file_path, \"r\") as f:\n",
    "        convs_data = json.load(f)\n",
    "\n",
    "    save_dir = \"./conversational_faq/openline-questions-fixed\"\n",
    "\n",
    "    convs_data_fix = convs_data.copy()\n",
    "\n",
    "    for turns_data in convs_data_fix:\n",
    "        for turn_data in turns_data[\"messages\"]:\n",
    "            if turn_data['role'] == \"user\":\n",
    "                context = turn_data['context']\n",
    "                recovered_texts = turn_data['recovered_texts']\n",
    "                max_idx = 0\n",
    "                \n",
    "                if recovered_texts is None:\n",
    "                    continue\n",
    "\n",
    "                for i, rt in enumerate(recovered_texts):\n",
    "                    if rt['text'] in context:\n",
    "                        max_idx = i\n",
    "                        #print(f\"{i}: encontrado\")\n",
    "                    #else:\n",
    "                        #print(f\"{i}: no encontrado\")\n",
    "\n",
    "                docs_range = [0, max_idx]\n",
    "                turn_data['docs_range'] = docs_range\n",
    "\n",
    "    base_name = os.path.basename(file_path)[:-5]\n",
    "    save_json(save_dir, base_name, convs_data_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "context =  \"\\n\\nRequisitos Y Procedimiento Para Matricula Solo Para Ingresantes\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula para nuevos ingresantes de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos nuevos estudiantes de pregrado ingresantes a la Facultad de Ciencias deber\\u00e1n seguir el siguiente proceso, por \\u00fanica vez, para completar su primera matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo la constancia de ingreso.\\n    2. Actualizaci\\u00f3n de datos en intranet. DIRCE har\\u00e1 llegar a su correo su clave para acceder a la plataforma de intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica de la facultad enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro (S/. 55.00) en el plazo establecido en el cronograma. Para ello, primero generar una orden de pago a traves de la plataforma intranet-alumnos.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula para ingresantes publicado dentro de la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Constancia de Ingreso\\n        - Ficha de datos\\n        - Constancia de Evaluaci\\u00f3n Socioecon\\u00f3mica\\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI\\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. La oficina de estad\\u00edstica ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un correo con el horario de sus cursos y tambi\\u00e9n podr\\u00e1n visualizar sus cursos y horarios en la plataforma intranet-alumnos.\\n\\nRequisitos Y Procedimiento De Matricula Para Estudiantes Regulares\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula regular al ciclo acad\\u00e9mico para alumnos regulares de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos estudiantes regulares de pregrado en la Facultad de Ciencias de la UNI deben cumplir con siguientes requisitos y procedimiento para realizar su matr\\u00edcula al ciclo acad\\u00e9mico.\\n\\nRequisitos para la matricula:\\n1. Haber efectuado el pago del autoseguro estudiantil mediante la plataforma intranet-alumnos.\\n\\n2. No tener adeudos pendientes con la Facultad, ya sea por concepto econ\\u00f3mico, pr\\u00e9stamos de libros u otros materiales de ense\\u00f1anza en general de la biblioteca.\\n\\n3. En caso de estar en riesgo acad\\u00e9mico, haber completado la tutor\\u00eda obligatoria previa a la matr\\u00edcula.\\n\\n4. Si el estudiante ha dejado de estudiar, reservado matr\\u00edcula o solicitado retiro total en el \\u00faltimo per\\u00edodo, deber\\u00e1 tramitar previamente su reincorporaci\\u00f3n a trav\\u00e9s de la plataforma intranet-alumnos.\\n\\nProcedimiento para la matr\\u00edcula regular:\\n1. Generar la orden de pago del autoseguro estudiantil a trav\\u00e9s de la plataforma INTRALU. Para ello, haz clic en \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de tr\\u00e1mites y pagos. Luego, selecciona el tr\\u00e1mite correspondiente, haz clic en \\\"Nuevo\\\" y sigue las instrucciones para completar el proceso.\\n2. Realizar el pago del autoseguro dentro del plazo establecido en el calendario de actividades acad\\u00e9micas, acerc\\u00e1ndose a un sucursal del BCP o a traves de la aplicaci\\u00f3n movil del banco. No se requiere la entrega del voucher de pago del autoseguro ni otros documentos.\\n3. En la fecha y turno asignado, el estudiante llevar\\u00e1 a cabo a su matr\\u00edcula de forma virtual, es decir, realizar\\u00e1 la inscripci\\u00f3n de sus cursos a trav\\u00e9s de la plataforma intranet-alumnos. Acceder\\u00e1 al m\\u00f3dulo de Matr\\u00edcula UNI dentro de esta plataforma, seleccionar\\u00e1 las asignaturas y horarios deseados, y finalizar\\u00e1 confirmando la matr\\u00edcula en todas las asignaturas elegidas en el sistema.\\n\\nLos turnos de matr\\u00edcula se asignan por grupos seg\\u00fan el promedio ponderado de los dos \\u00faltimos ciclos acad\\u00e9micos, en orden de m\\u00e9rito. Los estudiantes pueden consultarlos en el m\\u00f3dulo de Matr\\u00edcula UNI de la intranet-alumnos.\\n\\nMatricula Ingresantes\\nLos nuevos ingresantes a la Facultad de Ciencias de la Universidad Nacional de Ingenieria, deberan seguir realizar el siguiente proceso para completar su matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo electr\\u00f3nico la constancia de ingreso. Para m\\u00e1s detalles sobre el proceso, puede consultar con DIAD al correo informes.admision@uni.edu.pe. \\n    2. Actualizacion de datos en DIRCE. La Direcci\\u00f3n de Registros Central y Estad\\u00edstica har\\u00e1 llegar a su correo su clave para acceder a la plataforma para intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro dentro del plazo establecido en el cronograma de actividades academicas publicado en la pagina web de la Facultad de ciencias. Para ello, el ingresante debera generar una orden de pago atravez del portal INTRALU, luego podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula de ingresantes publicado en la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Contancia de Ingreso\\n        - Ficha de datos Personales. Enviada por la oficina de estad\\u00edstica al correo del ingresante.\\n        - Constancia de Evaluacion Socioeconomica. El ingresante debera acudir a la cita para su evaluacion socioeconomica que le llegara a su correo. \\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI. Para ello acudir a su examen medico segun los cronograma publicados por la Direcci\\u00f3n de Admisi\\u00f3n. \\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. AERA ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un mensaje en su correo con el horario de sus cursos, ademas podran visualizar los cursos y horarios dentro del portal INTRALU.\\n\\nPara generar una orden de pago, el ingresante debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opci\\u00f3n \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de pagos. En dicho m\\u00f3dulo, selecciona el tr\\u00e1mite correspondiente en el men\\u00fa desplegable, haz clic en el bot\\u00f3n \\\"Nuevo\\\" y sigue las indicaciones hasta generar la orden de pago. Para mas detalles sobre el proceso para generar un orden de pogo puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\\n\\n\\nTraslado Interno Procedimiento Y Requisitos\\n\\u00bfC\\u00f3mo es el procedimiento para que un estudiante de pregrado de la Facultad de Ciencias realice un traslado interno a otra carrera dentro de la misma Facultad?\\nPara llevar a cabo un traslado interno, un estudiante de la Facultad de Ciencias deber\\u00e1 seguir el siguiente procedimiento:\\n1. Realizar el pago correspondiente por concepto de primer o segundo traslado interno, seg\\u00fan sea el caso (S/ 125.20 o S/ 300.00). Para ello, el estudiante deber\\u00e1 generar una orden de pago a trav\\u00e9s de la plataforma INTRALU y efectuar el pago en una agencia del BCP o mediante el aplicativo m\\u00f3vil del banco.\\n2. El estudiante deber\\u00e1 presentar su solicitud a trav\\u00e9s de el plataforma intranet-alumnos, eligiendo la opci\\u00f3n \\\"Traslado Interno\\\" en el men\\u00fa \\\"Mis Tr\\u00e1mites\\\". Esta solicitud deber\\u00e1 ser enviada a traves de la plataforma en la fecha indicada en el calendario de actividades acad\\u00e9micas, adjuntando el comprobante de pago por concepto de traslado interno y la ficha acad\\u00e9mica.\\n3. La Escuela verificar\\u00e1 los documentos y requisitos propios dentro del primer d\\u00eda \\u00fatil de presentada la solicitud, registrar\\u00e1 el expediente y remitir\\u00e1 un correo de recepci\\u00f3n al interesado.\\n4. El director de Escuela o la Comisi\\u00f3n de Matr\\u00edcula analizar\\u00e1n las solicitudes y, utilizando el formato disponible en la web DIRCE, inscribir\\u00e1n las convalidaciones pertinentes seg\\u00fan el Avance Curricular del alumno, las notas y las normas de Convalidaci\\u00f3n.\\n5. Con la autorizaci\\u00f3n del director, el expediente ser\\u00e1 enviado al Decano y posteriormente presentado ante el Consejo de Facultad para su aprobaci\\u00f3n mediante Resoluci\\u00f3n Decanal y remisi\\u00f3n a la DIRCE.\\n6. La DIRCE ejecutar\\u00e1 el cambio de especialidad y realizar\\u00e1 las convalidaciones.\\n7. La Oficina de Estad\\u00edstica gestionar\\u00e1 la matr\\u00edcula de los estudiantes por traslado interno en funci\\u00f3n a la solicitud de matr\\u00edcula del director de la Escuela Profesional, y finalmente, la DIRCE realizar\\u00e1 la ejecuci\\u00f3n de la matr\\u00edcula en el sistema SIGA.\\n8. No se recibir\\u00e1n solicitudes extempor\\u00e1neas.\\nEscuelas Profesionales de la Facultad de Ciencias de la UNI\\n\\nInformaci\\u00f3n de Contacto:\\nSeg\\u00fan la escuela profesional (carrera universitaria), el correo de contacto es el siguiente:\\n\\nPara F\\u00edsica, Qu\\u00edmica o Ciencia de la Computaci\\u00f3n: escuelas_fc1@uni.edu.pe\\nPara Matem\\u00e1ticas o Ingenier\\u00eda F\\u00edsica: escuelas_fc2@uni.edu.pe\\n\\nHorario de Atenci\\u00f3n de Escuelas Profesionales: De Lunes a Viernes de 8:30 a.m a 4:00 p.m\\n\\n\\u00c1rea de Estad\\u00edstica y Registros Acad\\u00e9micos de la Facultad de Ciencias de la UNI\\n\\nInformaci\\u00f3n de Contacto de la oficina de estad\\u00edstica (AERA)\\nE-mail: estadistica_fc@uni.edu.pe\\n\\nHorario de Atenci\\u00f3n de la oficina de estad\\u00edstica (AERA):\\nDe Lunes a Viernes de 8:00 a.m. a 4:00 p.m.\"\n",
    "recovered_texts = [\n",
    "                    {\n",
    "                        \"text\": \"Requisitos Y Procedimiento Para Matricula Solo Para Ingresantes\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula para nuevos ingresantes de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos nuevos estudiantes de pregrado ingresantes a la Facultad de Ciencias deber\\u00e1n seguir el siguiente proceso, por \\u00fanica vez, para completar su primera matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo la constancia de ingreso.\\n    2. Actualizaci\\u00f3n de datos en intranet. DIRCE har\\u00e1 llegar a su correo su clave para acceder a la plataforma de intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica de la facultad enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro (S/. 55.00) en el plazo establecido en el cronograma. Para ello, primero generar una orden de pago a traves de la plataforma intranet-alumnos.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula para ingresantes publicado dentro de la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Constancia de Ingreso\\n        - Ficha de datos\\n        - Constancia de Evaluaci\\u00f3n Socioecon\\u00f3mica\\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI\\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. La oficina de estad\\u00edstica ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un correo con el horario de sus cursos y tambi\\u00e9n podr\\u00e1n visualizar sus cursos y horarios en la plataforma intranet-alumnos.\",\n",
    "                        \"relatedness\": 0.7661936283111572\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Requisitos Y Procedimiento De Matricula Para Estudiantes Regulares\\n\\u00bfCuales son los requisitos y el proceso de matr\\u00edcula regular al ciclo acad\\u00e9mico para alumnos regulares de pregrado en la Facultad de Ciencias de la Universidad Nacional de Ingenier\\u00eda?\\nLos estudiantes regulares de pregrado en la Facultad de Ciencias de la UNI deben cumplir con siguientes requisitos y procedimiento para realizar su matr\\u00edcula al ciclo acad\\u00e9mico.\\n\\nRequisitos para la matricula:\\n1. Haber efectuado el pago del autoseguro estudiantil mediante la plataforma intranet-alumnos.\\n\\n2. No tener adeudos pendientes con la Facultad, ya sea por concepto econ\\u00f3mico, pr\\u00e9stamos de libros u otros materiales de ense\\u00f1anza en general de la biblioteca.\\n\\n3. En caso de estar en riesgo acad\\u00e9mico, haber completado la tutor\\u00eda obligatoria previa a la matr\\u00edcula.\\n\\n4. Si el estudiante ha dejado de estudiar, reservado matr\\u00edcula o solicitado retiro total en el \\u00faltimo per\\u00edodo, deber\\u00e1 tramitar previamente su reincorporaci\\u00f3n a trav\\u00e9s de la plataforma intranet-alumnos.\\n\\nProcedimiento para la matr\\u00edcula regular:\\n1. Generar la orden de pago del autoseguro estudiantil a trav\\u00e9s de la plataforma INTRALU. Para ello, haz clic en \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de tr\\u00e1mites y pagos. Luego, selecciona el tr\\u00e1mite correspondiente, haz clic en \\\"Nuevo\\\" y sigue las instrucciones para completar el proceso.\\n2. Realizar el pago del autoseguro dentro del plazo establecido en el calendario de actividades acad\\u00e9micas, acerc\\u00e1ndose a un sucursal del BCP o a traves de la aplicaci\\u00f3n movil del banco. No se requiere la entrega del voucher de pago del autoseguro ni otros documentos.\\n3. En la fecha y turno asignado, el estudiante llevar\\u00e1 a cabo a su matr\\u00edcula de forma virtual, es decir, realizar\\u00e1 la inscripci\\u00f3n de sus cursos a trav\\u00e9s de la plataforma intranet-alumnos. Acceder\\u00e1 al m\\u00f3dulo de Matr\\u00edcula UNI dentro de esta plataforma, seleccionar\\u00e1 las asignaturas y horarios deseados, y finalizar\\u00e1 confirmando la matr\\u00edcula en todas las asignaturas elegidas en el sistema.\\n\\nLos turnos de matr\\u00edcula se asignan por grupos seg\\u00fan el promedio ponderado de los dos \\u00faltimos ciclos acad\\u00e9micos, en orden de m\\u00e9rito. Los estudiantes pueden consultarlos en el m\\u00f3dulo de Matr\\u00edcula UNI de la intranet-alumnos.\",\n",
    "                        \"relatedness\": 0.649982213973999\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Matricula Ingresantes\\nLos nuevos ingresantes a la Facultad de Ciencias de la Universidad Nacional de Ingenieria, deberan seguir realizar el siguiente proceso para completar su matricula (primera matricula al primer ciclo):\\n    1. Recabar su constancia de ingreso. Luego de gestionar la emisi\\u00f3n de su constancia de ingreso, la Direcci\\u00f3n de Admisi\\u00f3n (DIAD) de la UNI enviar\\u00e1 a su correo electr\\u00f3nico la constancia de ingreso. Para m\\u00e1s detalles sobre el proceso, puede consultar con DIAD al correo informes.admision@uni.edu.pe. \\n    2. Actualizacion de datos en DIRCE. La Direcci\\u00f3n de Registros Central y Estad\\u00edstica har\\u00e1 llegar a su correo su clave para acceder a la plataforma para intranet-alumnos y completar sus datos.\\n    3. Registrar los datos en la Facultad de Ciencias. La oficina de estad\\u00edstica enviar\\u00e1 al correo del ingresante la ficha de datos. El llenado es car\\u00e1cter obligatorio.\\n    4. Efectuar el pago por autoseguro dentro del plazo establecido en el cronograma de actividades academicas publicado en la pagina web de la Facultad de ciencias. Para ello, el ingresante debera generar una orden de pago atravez del portal INTRALU, luego podra realizar el pago por aplicativo movil BCP o en alguna sucursal de la entidad bancaria.\\n    5. Realizar la entrega de los siguientes documentos a la oficina de estad\\u00edstica seg\\u00fan el cronograma de actividades de matr\\u00edcula de ingresantes publicado en la secci\\u00f3n 'MATR\\u00cdCULA Y PROCEDIMIENTOS' en la p\\u00e1gina web de la Facultad de Ciencias.\\n        - Contancia de Ingreso\\n        - Ficha de datos Personales. Enviada por la oficina de estad\\u00edstica al correo del ingresante.\\n        - Constancia de Evaluacion Socioeconomica. El ingresante debera acudir a la cita para su evaluacion socioeconomica que le llegara a su correo. \\n        - Certificado M\\u00e9dico expedido por el Centro Medico UNI. Para ello acudir a su examen medico segun los cronograma publicados por la Direcci\\u00f3n de Admisi\\u00f3n. \\n        - Comprobante de pago de Autoseguro Estudiantil\\n    6. AERA ejecutar\\u00e1 la matr\\u00edcula (inscripci\\u00f3n de cursos) de los ingresantes seg\\u00fan el cronograma de actividades, \\u00fanicamente para aquellos que hayan cumplido con la entrega de la entrega de los documentos requeridos en de las fechas establecidas en el cronograma.\\n    7. Los ingresantes matriculados recibir\\u00e1n un mensaje en su correo con el horario de sus cursos, ademas podran visualizar los cursos y horarios dentro del portal INTRALU.\\n\\nPara generar una orden de pago, el ingresante debe ingresar a la plataforma INTRALU. En esta plataforma, selecciona la opci\\u00f3n \\\"Tr\\u00e1mites\\\" para acceder al m\\u00f3dulo de pagos. En dicho m\\u00f3dulo, selecciona el tr\\u00e1mite correspondiente en el men\\u00fa desplegable, haz clic en el bot\\u00f3n \\\"Nuevo\\\" y sigue las indicaciones hasta generar la orden de pago. Para mas detalles sobre el proceso para generar un orden de pogo puede revisar el manual de pagos de la UNI publicado en la pagina web de la Facultad de Ciencias.\\n\",\n",
    "                        \"relatedness\": 0.6069541811943054\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Traslado Interno Procedimiento Y Requisitos\\n\\u00bfC\\u00f3mo es el procedimiento para que un estudiante de pregrado de la Facultad de Ciencias realice un traslado interno a otra carrera dentro de la misma Facultad?\\nPara llevar a cabo un traslado interno, un estudiante de la Facultad de Ciencias deber\\u00e1 seguir el siguiente procedimiento:\\n1. Realizar el pago correspondiente por concepto de primer o segundo traslado interno, seg\\u00fan sea el caso (S/ 125.20 o S/ 300.00). Para ello, el estudiante deber\\u00e1 generar una orden de pago a trav\\u00e9s de la plataforma INTRALU y efectuar el pago en una agencia del BCP o mediante el aplicativo m\\u00f3vil del banco.\\n2. El estudiante deber\\u00e1 presentar su solicitud a trav\\u00e9s de el plataforma intranet-alumnos, eligiendo la opci\\u00f3n \\\"Traslado Interno\\\" en el men\\u00fa \\\"Mis Tr\\u00e1mites\\\". Esta solicitud deber\\u00e1 ser enviada a traves de la plataforma en la fecha indicada en el calendario de actividades acad\\u00e9micas, adjuntando el comprobante de pago por concepto de traslado interno y la ficha acad\\u00e9mica.\\n3. La Escuela verificar\\u00e1 los documentos y requisitos propios dentro del primer d\\u00eda \\u00fatil de presentada la solicitud, registrar\\u00e1 el expediente y remitir\\u00e1 un correo de recepci\\u00f3n al interesado.\\n4. El director de Escuela o la Comisi\\u00f3n de Matr\\u00edcula analizar\\u00e1n las solicitudes y, utilizando el formato disponible en la web DIRCE, inscribir\\u00e1n las convalidaciones pertinentes seg\\u00fan el Avance Curricular del alumno, las notas y las normas de Convalidaci\\u00f3n.\\n5. Con la autorizaci\\u00f3n del director, el expediente ser\\u00e1 enviado al Decano y posteriormente presentado ante el Consejo de Facultad para su aprobaci\\u00f3n mediante Resoluci\\u00f3n Decanal y remisi\\u00f3n a la DIRCE.\\n6. La DIRCE ejecutar\\u00e1 el cambio de especialidad y realizar\\u00e1 las convalidaciones.\\n7. La Oficina de Estad\\u00edstica gestionar\\u00e1 la matr\\u00edcula de los estudiantes por traslado interno en funci\\u00f3n a la solicitud de matr\\u00edcula del director de la Escuela Profesional, y finalmente, la DIRCE realizar\\u00e1 la ejecuci\\u00f3n de la matr\\u00edcula en el sistema SIGA.\\n8. No se recibir\\u00e1n solicitudes extempor\\u00e1neas.\",\n",
    "                        \"relatedness\": 0.6002129912376404\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Procedimiento Para Solicitar Una Constancia De Matricula En La Facultad De Ciencias De La Uni\\n\\u00bfQu\\u00e9 procedimiento debe seguir un estudiante para solicitar una constancia de Matricula en ingles o en espa\\u00f1ol?\\nPara solicitar una constancia de matr\\u00edcula en ingl\\u00e9s o en espa\\u00f1ol, el estudiante deber seguir los siguientes pasos:\\n\\n1. Enviar un correo a estadistica_fc@uni.edu.pe solicitando una orden de pago para la CONSTANCIA DE MATR\\u00cdCULA. En el mensaje, deber\\u00e1 incluir sus datos personales: n\\u00famero de DNI, apellidos, nombres, correo institucional y/o alternativo.\\n\\n2. La oficina de estad\\u00edstica (AERA) le enviar\\u00e1 la orden de pago por el monto correspondiente al correo electr\\u00f3nico del estudiante.\\n\\n3. Realize el pago en alguna sucursal del BCP o a trav\\u00e9s aplicaci\\u00f3n movil del banco. En la app selecciona \\\"Pagar servicios\\\", elige la Universidad Nacional de Ingenier\\u00eda, luego la opci\\u00f3n de pago para estudiantes, e ingresa su n\\u00famero de DNI. La app mostrar\\u00e1 la orden de pago con el monto exacto para realizar el pago.\\n\\n4. Luego, deber\\u00e1 enviar la solicitud correspondiente a mesa de partes de la facultad de ciencias al correo mesadepartes_fc@uni.edu.pe. Es importante que se asegure de indicar en la solicitud si desea la CONSTANCIA DE MATR\\u00cdCULA en ingl\\u00e9s o espa\\u00f1ol. El modelo para esta solicitud est\\u00e1 disponible dentro de la secci\\u00f3n [\\\"MATR\\u00cdCULA Y PROCEDIMIENTOS\\\" en la p\\u00e1gina web de la Facultad de Ciencias](https://fc.uni.edu.pe/estadistica/documentos/).\\n\\n5. Por \\u00faltimo, la constancia se enviar\\u00e1 al correo institucional del estudiante.\",\n",
    "                        \"relatedness\": 0.5496701002120972\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Proceso De Matricula\\nDe los Requisitos de la Matr\\u00edcula\\nArt. 46\\u00b0 La ense\\u00f1anza en el antegrado es gratuita para la primera carrera profesional. Son requisitos para la matr\\u00edcula, los siguientes:\\n\\ta. Cumplir con los requisitos acad\\u00e9micos establecidos en el presente reglamento .\\n\\tb. Realizar el pago por concepto de Autoseguro M\\u00e9dico. En caso de inconvenientes, presentar por correo o de forma f\\u00edsica el recibo de pago.\\n\\tc. En caso de la matricula regular, reincorporaci\\u00f3n o traslado interno, no presentar adeudos con su Facultad (econ\\u00f3mico, libros, enseres, o material de ense\\u00f1anza en general)\\n\\td. Aquellos estudiantes que no puedan cumplir con las deudas del tipo econ\\u00f3mico podr\\u00e1n solicitar, con diez (1O) d\\u00edas \\u00fatiles de anticipaci\\u00f3n, facilidades a la Comisi\\u00f3n de Matr\\u00edcula y comprometerse a una forma de pago a plazos, evitando que sea una restricci\\u00f3n de su matr\\u00edcula. Esta ventaja se perder\\u00e1 si no hubiese cumplido con similar compromiso en su anterior matr\\u00edcula.\\n\\te. En el caso de los traslados internos, externos, graduados, titulados, convenios internacionales, adem\\u00e1s de los incisos anteriores, deben presentar la Constancia o la Resoluci\\u00f3n Directora! de convalidaci\\u00f3n de las asignaturas. \\n\\tf. Los estudiantes que realizan su matr\\u00edcula en forma rezagada deber\\u00e1n efectuar el pago correspondiente establecido en las normas de la UNI. \\n\\tg. Los estudiantes que hayan dejado de estudiar, o reservado matr\\u00edcula o hayan solicitado su retiro total en alg\\u00fan periodo anterior, deber\\u00e1n previamente haber solicitado su reincorporaci\\u00f3n ante su Decano y su tr\\u00e1mite lo realizar\\u00e1 v\\u00eda la plataforma DIRCE-UNI.\\n\\t\\t Si requiriesen cambio previo de Plan de Estudios y convalidaciones correspondientes, \\u00e9stas ya deben haberse tramitado. En estos casos , el tr\\u00e1mite de reincorporaci\\u00f3n debe hacerse con no menos de una semana adicional de anticipaci\\u00f3n.\\n\\th. El pago del carn\\u00e9 universitario no es requisito para la matr\\u00edcula.\\n\\ti. No ser\\u00e1 necesario que los estudiantes hayan participado en el \\u00faltimo proceso electoral para ser matriculados, sin que esto signifique exonerarlo de la multa correspondiente. \\n\\tj. Otros de acuerdo con lo establecido en las normas de la UNI.\",\n",
    "                        \"relatedness\": 0.5412235915660858\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Matricula Ingresantes\\n                MATR\\u00cdCULA DE INGRESANTES\\n(del Reglamento de Matr\\u00edcula Aprobado R.R. No0570 del 29.03.2022 y las modificacion de la Resoluci\\u00f3n Rectoral N\\u00b0 3084-2024-UNI)\\n\\nArt\\u00edculo 7\\u00b0: La matr\\u00edcula de ingresantes es el procedimiento a trav\\u00e9s del cual el ingresante acredita su condici\\u00f3n de estudiante al inscribirse en un periodo acad\\u00e9mico, en las fechas establecidas en el calendario de actividades acad\\u00e9micas seg\\u00fan la facultad que le corresponde, para matricularse no es obligatorio tomar el m\\u00e1ximo de cr\\u00e9ditos permitidos. La matr\\u00edcula implica el cumplimiento de la Ley Universitaria y es el resultado de un acto formal que es ejecutado personal y voluntariamente por el estudiante, sujeto a verificaci\\u00f3n posterior. Implica el cumplimiento de la Ley Universitaria, el Estatuto, las normas de la UNI y el presente reglamento.\\n\\n-----------------------------------------------------------------------------------------------------------------------------------------------\\n\\nProcedimiento de Matricula Para Ingresantes\",\n",
    "                        \"relatedness\": 0.531317925453186\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Procedimiento Para Solicitar El Correo Institucional\\n\\u00bfQu\\u00e9 procedimiento debe seguir un estudiante de la UNI para solicitar su correo institucional?\\nPara solicitar su correo institucional de la UNI, enviar un correo obtenercorreo@uni.pe proporcionando la siguiente informaci\\u00f3n:\\n    C\\u00f3digo de Alumno.\\n    Nombres y Apellidos.\\n    DNI.\\n    Especialidad.\\n    Indicar si es estudiante de pregrado o posgrado.\\n    Correo personal (que no sea @uni.pe ni @UNI.PE) donde se le enviar\\u00e1 la clave.\\n    N\\u00famero de Celular.\\n    Facultad.\",\n",
    "                        \"relatedness\": 0.5192470550537109\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Proceso De Matricula\\n\\tTodas las deudas pendientes del estudiante ser\\u00e1n exigidas al finalizar sus estudios e iniciar el tr\\u00e1mite para obtener de su grado de bachiller.\\n\\nDel Proceso de la Matr\\u00edcula Regular para Estudiantes de Antegrado\\n(del Reglamento de Matr\\u00edcula Aprobado R.R. No0570 del 29.03.2022)\\n\\nArt. 47\\u00b0 La matr\\u00edcula regular se realiza v\\u00eda internet a trav\\u00e9s del Sistema de Matr\\u00edcula UNI suministrado por DIRCE, en las fechas establecidas en el Calendario de Actividades de los Estudios de Antegrado de la UNI.\\nEste proceso es personal y se realizar puede desde cualquier equipo con acceso a internet y ser\\u00e1 bajo responsabilidad del estudiante, cumpliendo los siguientes pasos: \\n\\ta. Ingresar al Sistema de Matr\\u00edcula UNI seg\\u00fan el turno programado.\\n\\tb. En su Oferta de Matr\\u00edcula, seleccionar las asignaturas-secci\\u00f3n, comenzando por las obligatorias y de menor ciclo.\\n\\tc. Confirmar en el sistema la matr\\u00edcula en las asignaturas-secci\\u00f3n seleccionadas dentro del plazo establecido para dicho acto, consignando la secci\\u00f3n elegida.\\n\\td. El sistema presentar\\u00e1 el Reporte de Matr\\u00edcula del estudiante para su impresi\\u00f3n, remisi\\u00f3n , o archivo.\\n\\te. En caso de los estudiantes que est\\u00e1n en riesgo acad\\u00e9mico y de los que retornen de la suspensi\\u00f3n acad\\u00e9mica realizar\\u00e1n su matr\\u00edcula, seg\\u00fan lo coordinado con su respectivo tutor, quien autorizar\\u00e1 la activaci\\u00f3n de su c\\u00f3digo y supervisar\\u00e1 el respectivo Reporte.\",\n",
    "                        \"relatedness\": 0.4989213466644287\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"Traslado Interno\\nDetalle del procedimiento de Traslado Interno: \\n    1. Realizar el pago correspondiente por concepto de primer o segundo traslado interno, seg\\u00fan sea el caso (S/ 125.20 o S/ 300.00). Para ello, el estudiante deber\\u00e1 generar una orden de pago a trav\\u00e9s de la plataforma INTRALU y efectuar el pago en una agencia del BCP o mediante el aplicativo m\\u00f3vil del banco.\\n    2. El interesado presentar\\u00e1 su solicitud a trav\\u00e9s del intranet alumnos / tramites; hasta la fecha que indica el calendario acad\\u00e9mico. Adjuntando lo siguiente: \\n        \\u2212 Comprobante de pago por el concepto de Traslado Interno. \\n        \\u2212 Ficha Acad\\u00e9mica \\n    3. La Escuela, dentro del 1er d\\u00eda \\u00fatil de presentada verificar\\u00e1 documentos y requisitos propios, registrar\\u00e1 el expediente y remitir\\u00e1 correo de recepci\\u00f3n al interesado. Luego, si fuere necesario, solicitar\\u00e1 a otras Escuelas Profesionales de la UNI la remisi\\u00f3n de s\\u00edlabos pertinentes, si el director lo solicita y atender\\u00e1 similares solicitudes de otras Escuelas  \\n    4. El director de Escuela o la Comisi\\u00f3n de Matr\\u00edcula analizar\\u00e1 las solicitudes y haciendo uso del formato disponible en la web DIRCE, inscribir\\u00e1 las convalidaciones pertinentes, seg\\u00fan el Avance Curricular del alumno, las notas y las normas de Convalidaci\\u00f3n. Si quedan notas no registradas, ser\\u00e1n motivo de convalidaci\\u00f3n posterior a la matr\\u00edcula.  \\n    5. Con  la  autorizaci\\u00f3n  del  director,  el  expediente  es  enviado  al  Decano  y  posteriormente presentarlo ante el Consejo de Facultad para su aprobaci\\u00f3n (mediante Resoluci\\u00f3n Decanal) y remisi\\u00f3n a la DIRCE.  \\n    6. La DIRCE ejecutar\\u00e1 el cambio de especialidad y/o facultad y las convalidaciones.   \\n    7. Registradas las convalidaciones, la Oficina de Estad\\u00edstica gestiona la matr\\u00edcula de los sestudiantes por traslado interno en funci\\u00f3n a la solicitud de matr\\u00edcula del director de la Escuela Profesional, finalmente la DIRCE realiza la ejecuci\\u00f3n de la matr\\u00edcula en el sistema SIGA. \\n    8. No se recibir\\u00e1n solicitudes extempor\\u00e1neas \",\n",
    "                        \"relatedness\": 0.4829025506973267\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "print(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
